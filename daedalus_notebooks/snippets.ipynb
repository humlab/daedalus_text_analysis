{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "plt.figure(figsize=(4,4))\n",
    "v = venn3(subsets=(1, 1, 1, 1, 1, 1, 1), set_labels = ('A', 'B', 'C'))\n",
    "v.get_patch_by_id('100').set_alpha(1.0)\n",
    "v.get_patch_by_id('100').set_color('white')\n",
    "v.get_label_by_id('100').set_text('Unknown')\n",
    "v.get_label_by_id('A').set_text('Set \"A\"')\n",
    "c = venn3_circles(subsets=(1, 1, 1, 1, 1, 1, 1), linestyle='dashed')\n",
    "c[0].set_lw(1.0)\n",
    "c[0].set_ls('dotted')\n",
    "plt.title(\"Sample Venn diagram\")\n",
    "plt.annotate('Unknown set', xy=v.get_label_by_id('100').get_position() - np.array([0, 0.05]), xytext=(-70,-70),\n",
    "             ha='center', textcoords='offset points', bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.1),\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0.5',color='gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(['A', 'B', 'C', 'D'])\n",
    "set2 = set(['B', 'C', 'D', 'E'])\n",
    "set3 = set(['C', 'D',' E', 'F', 'G'])\n",
    "\n",
    "venn3([set1, set2, set3], ('Set1', 'Set2', 'Set3'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# DEMO: Zoom-Window\n",
    "import numpy as np\n",
    "\n",
    "from bokeh.layouts import row\n",
    "from bokeh.models import ColumnDataSource, CustomJS, Rect\n",
    "from bokeh.plotting import output_notebook, figure, show\n",
    "\n",
    "output_file('range_update_callback.html')\n",
    "\n",
    "N = 4000\n",
    "\n",
    "x = np.random.random(size=N) * 100\n",
    "y = np.random.random(size=N) * 100\n",
    "radii = np.random.random(size=N) * 1.5\n",
    "colors = [\n",
    "    \"#%02x%02x%02x\" % (int(r), int(g), 150) for r, g in zip(50+2*x, 30+2*y)\n",
    "]\n",
    "\n",
    "source = ColumnDataSource({'x': [], 'y': [], 'width': [], 'height': []})\n",
    "\n",
    "jscode=\"\"\"\n",
    "    var data = source.data;\n",
    "    var start = cb_obj.start;\n",
    "    var end = cb_obj.end;\n",
    "    data['%s'] = [start + (end - start) / 2];\n",
    "    data['%s'] = [end - start];\n",
    "    source.change.emit();\n",
    "\"\"\"\n",
    "\n",
    "p1 = figure(title='Pan and Zoom Here', x_range=(0, 100), y_range=(0, 100),\n",
    "            tools='box_zoom,wheel_zoom,pan,reset', plot_width=400, plot_height=400)\n",
    "p1.scatter(x, y, radius=radii, fill_color=colors, fill_alpha=0.6, line_color=None)\n",
    "\n",
    "p1.x_range.callback = CustomJS(\n",
    "        args=dict(source=source), code=jscode % ('x', 'width'))\n",
    "p1.y_range.callback = CustomJS(\n",
    "        args=dict(source=source), code=jscode % ('y', 'height'))\n",
    "\n",
    "p2 = figure(title='See Zoom Window Here', x_range=(0, 100), y_range=(0, 100),\n",
    "            tools='', plot_width=400, plot_height=400)\n",
    "p2.scatter(x, y, radius=radii, fill_color=colors, fill_alpha=0.6, line_color=None)\n",
    "rect = Rect(x='x', y='y', width='width', height='height', fill_alpha=0.1,\n",
    "            line_color='black', fill_color='black')\n",
    "p2.add_glyph(source, rect)\n",
    "\n",
    "layout = row(p1, p2)\n",
    "\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Godness of Fit\n",
    "Goodness of Fit using **Kolmogorov-Smirnov** (alternatives are **chi square** and **maximum likelihood**) \n",
    "\n",
    "https://stats.stackexchange.com/questions/113464/understanding-scipy-kolmogorov-smirnov-test\n",
    "*\"For the KS test the p-value is itself distributed uniformly in [0,1] if the H0 is true (which it is if you test whether it your sample is from U(0,1)U(0,1) and the random number generation works okay). It therefore must \"vary wildly\" between 0 and 1, in fact its standard deviation is 1/12−−√1/12 which is roughly 0.3.\"*\n",
    "\n",
    "https://en.m.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test\n",
    "*\"The Kolmogorov–Smirnov statistic quantifies a distance between the empirical distribution function of the sample and the cumulative distribution function of the reference distribution, or between the empirical distribution functions of two samples. The null distribution of this statistic is calculated under the null hypothesis that the sample is drawn from the reference distribution (in the one-sample case) or that the samples are drawn from the same distribution (in the two-sample case). In each case, the distributions considered under the null hypothesis are continuous distributions but are otherwise unrestricted....The Kolmogorov–Smirnov test can be modified to serve as a goodness of fit test. \"* \n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html\n",
    "\n",
    "scipy.stats.wasserstein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/113464/understanding-scipy-kolmogorov-smirnov-test\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "a = np.random.uniform(size=4999)\n",
    "\n",
    "print(scipy.stats.kstest(a, 'uniform'))\n",
    "\n",
    "rvs = df.loc[(df.document_id==0)]['weight']\n",
    "\n",
    "scipy.stats.kstest(rvs,'uniform')\n",
    "stats.kstest([1,2,3,4,5,6], 'uniform')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Clustering\n",
    "Compute topic clustering based on the distances between the T-SNE 2D coordinates. The SciPy linkage() takes an n x m matrice i.e. n points in m-dimensional vector space (can also take a 1D condensed distance matrix).\n",
    "\n",
    "1. The first plot takes the num_topics x 2 matrix that T-SNE produced as input\n",
    "2. The second example takes the \"raw\" vectorized num_topics x num_words matrix  as input i.e same input as to T-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Compute hierarchical/agglomerative clustering.\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html\n",
    "# https://stackoverflow.com/questions/11917779/how-to-plot-and-annotate-hierarchical-clustering-dendrograms-in-scipy-matplotlib\n",
    "\n",
    "if False:\n",
    "    C = linkage(X_reduced, method='single', metric='euclidean', optimal_ordering=False)\n",
    "else:\n",
    "    n_words = 50\n",
    "    X_n_space, _ = ModelUtility.compute_topic_terms_vector_space(state.get_lda(), n_words)\n",
    "    C = linkage(X_n_space.toarray(), method='single', metric='euclidean', optimal_ordering=False)\n",
    "    \n",
    "plt.figure(figsize=(24,12))\n",
    "R = dendrogram(C, orientation='left')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Code\n",
    "import pandas as pd\n",
    "from bokeh.layouts import row\n",
    "category_size = 100\n",
    "\n",
    "topic_weights = state.get_document_topic_weights()[['document_id', 'topic_id', 'weight']]\n",
    "\n",
    "sd = topic_weights.weight.apply(lambda x: int(category_size * x))\n",
    "s_count = len(topic_weights)\n",
    "\n",
    "sd = sd[sd>0]\n",
    "v_count = len(sd)\n",
    "x_count = s_count - v_count\n",
    "d_count = len(topic_weights.document_id.unique())\n",
    "t_count = len(topic_weights.topic_id.unique())\n",
    "\n",
    "print('The data consists of {} documents, {} topics giving {} topic shares'.format(d_count, t_count, s_count))\n",
    "print('As much as {0:.2f}% of the documents topic shares are 0 ({1} out of {2})'.format(\n",
    "    100*x_count/s_count,x_count,s_count))\n",
    "print(\"The following graphs show the distribution of topic shares in absolute number and percentages\")\n",
    "\n",
    "ys = sd[sd>0].groupby(sd).size()\n",
    "xs = ys.index\n",
    "ysp = ys.apply(lambda x: x/v_count)\n",
    "\n",
    "p1 = figure(width=400, height=400, tools='',\n",
    "    x_axis_label='Number of topic shares',\n",
    "    y_axis_label='Percentage of all topics having that share')\n",
    "\n",
    "cd = p1.vbar(x=xs,width=1,top=ys,line_width=2)\n",
    "            \n",
    "p2 = figure(width=400, height=400, tools='',\n",
    "    x_axis_label='Topic''s share in document (percentage)',\n",
    "    y_axis_label='Percentage of all topics having that share')\n",
    "\n",
    "cd = p2.line(x=xs, y=ysp, line_width=2)\n",
    "show(row(p1,p2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grubbs Outlier Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "# Grubs Test\n",
    "import numpy as np\n",
    "from scipy.stats import t, zscore\n",
    " \n",
    " \n",
    "def grubbs(X, test='two-tailed', alpha=0.05):\n",
    " \n",
    "    '''\n",
    "    Performs Grubbs' test for outliers recursively until the null hypothesis is\n",
    "    true.\n",
    " \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        A numpy array to be tested for outliers.\n",
    "    test : str\n",
    "        Describes the types of outliers to look for. Can be 'min' (look for\n",
    "        small outliers), 'max' (look for large outliers), or 'two-tailed' (look\n",
    "        for both).\n",
    "    alpha : float\n",
    "        The significance level.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    X : ndarray\n",
    "        The original array with outliers removed.\n",
    "    outliers : ndarray\n",
    "        An array of outliers.\n",
    "    '''\n",
    " \n",
    "    Z = zscore(X, ddof=1)  # Z-score\n",
    "    N = len(X)  # number of samples\n",
    " \n",
    "    # calculate extreme index and the critical t value based on the test\n",
    "    if test == 'two-tailed':\n",
    "        extreme_ix = lambda Z: np.abs(Z).argmax()\n",
    "        t_crit = lambda N: t.isf(alpha / (2.*N), N-2)\n",
    "    elif test == 'max':\n",
    "        extreme_ix = lambda Z: Z.argmax()\n",
    "        t_crit = lambda N: t.isf(alpha / N, N-2)\n",
    "    elif test == 'min':\n",
    "        extreme_ix = lambda Z: Z.argmin()\n",
    "        t_crit = lambda N: t.isf(alpha / N, N-2)\n",
    "    else:\n",
    "        raise ValueError(\"Test must be 'min', 'max', or 'two-tailed'\")\n",
    " \n",
    "    # compute the threshold\n",
    "    thresh = lambda N: (N - 1.) / np.sqrt(N) * \\\n",
    "        np.sqrt(t_crit(N)**2 / (N - 2 + t_crit(N)**2))\n",
    " \n",
    "    # create array to store outliers\n",
    "    outliers = np.array([])\n",
    " \n",
    "    # loop throught the array and remove any outliers\n",
    "    while abs(Z[extreme_ix(Z)]) > thresh(N):\n",
    " \n",
    "        # update the outliers\n",
    "        outliers = np.r_[outliers, X[extreme_ix(Z)]]\n",
    "        # remove outlier from array\n",
    "        X = np.delete(X, extreme_ix(Z))\n",
    "        # repeat Z score\n",
    "        Z = zscore(X, ddof=1)\n",
    "        N = len(X)\n",
    " \n",
    "    return X, outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Connector Arrow to Node Circumference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Code\n",
    "'''\n",
    "[x1, x2], {y1, y2}, R\n",
    "\n",
    "\n",
    "y = k * x + m\n",
    "\n",
    "R^2 = (y2 - y0)^2 +  (x2 - x0)^2\n",
    "\n",
    "\n",
    "y1 = k * x1 + m\n",
    "y2 = k * x2 + m\n",
    "\n",
    "y2 = k * x2 + y1 - k * x1\n",
    "y2 - y1 = k * x2 - k * x1 = k * (x2 - x1)\n",
    "k = (y2 - y1) / (x2 - x1)\n",
    "m = y1 - k * x1\n",
    "'''\n",
    "def adjust_connector_line(xs, ys,radius):\n",
    "    x1, x2 = xs\n",
    "    y1, y2 = ys\n",
    "    dx, dy = x2 - x1, y2 - y1\n",
    "    length = math.sqrt(dx * dx + dy * dy)\n",
    "    if (length > 0):\n",
    "        dx /= length\n",
    "        dy /= length\n",
    "    dx *= radius #length - radius\n",
    "    dy *= radius #length - radius\n",
    "    return [x1 + dx, x2 - dx], [y1 + dy, y2 - dy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.sampledata.glucose import data\n",
    "from bokeh.sampledata.iris import flowers\n",
    "\n",
    "from bokeh.io import show, output_file\n",
    "from bokeh.layouts import layout\n",
    "from bokeh.models import ColumnDataSource, Paragraph, HoverTool, Div\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "output_file(\"words_and_plots.html\")\n",
    "\n",
    "\n",
    "def text():\n",
    "    return Paragraph(text=\"\"\"\n",
    "        Bacon ipsum dolor amet hamburger brisket prosciutto, pork ball tip andouille\n",
    "        sausage landjaeger filet mignon ribeye ground round. Jerky fatback cupim\n",
    "        landjaeger meatball pork loin corned beef, frankfurter short ribs short loin\n",
    "        bresaola capicola chuck kevin. Andouille biltong turkey, tail t-bone ribeye\n",
    "        short loin tongue prosciutto kielbasa short ribs boudin. Swine beef ribs\n",
    "        tri-tip filet mignon bresaola boudin beef meatball venison leberkas fatback\n",
    "        strip steak landjaeger drumstick prosciutto.\n",
    "        Bacon ipsum dolor amet hamburger brisket prosciutto, pork ball tip andouille\n",
    "        sausage landjaeger filet mignon ribeye ground round. Jerky fatback cupim\n",
    "        landjaeger meatball pork loin corned beef, frankfurter short ribs short loin\n",
    "        bresaola capicola chuck kevin. Andouille biltong turkey, tail t-bone ribeye\n",
    "        short loin tongue prosciutto kielbasa short ribs boudin. Swine beef ribs\n",
    "        tri-tip filet mignon bresaola boudin beef meatball venison leberkas fatback\n",
    "        strip steak landjaeger drumstick prosciutto.\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "def scatter():\n",
    "    colormap = {'setosa': 'red', 'versicolor': 'green', 'virginica': 'blue'}\n",
    "    source = ColumnDataSource(flowers)\n",
    "    source.data['colors'] = [colormap[x] for x in flowers['species']]\n",
    "    s = figure(title = \"Iris Morphology\")\n",
    "    s.xaxis.axis_label = 'Petal Length'\n",
    "    s.yaxis.axis_label = 'Petal Width'\n",
    "    s.circle(\"petal_length\", \"petal_width\", color=\"colors\", source=source,\n",
    "             fill_alpha=0.2, size=10, legend=\"species\")\n",
    "    # Lets move the legend off-canvas!\n",
    "    legend = s.legend[0]\n",
    "    legend.border_line_color = None\n",
    "    legend.orientation = 'horizontal'\n",
    "    legend.location = 'center_left'\n",
    "    s.above.append(legend)\n",
    "    return s\n",
    "\n",
    "\n",
    "def hover_plot():\n",
    "    x = data.ix['2010-10-06'].index.to_series()\n",
    "    y = data.ix['2010-10-06']['glucose']\n",
    "    p = figure(\n",
    "        plot_width=800, plot_height=400, x_axis_type=\"datetime\",\n",
    "        tools=\"\", toolbar_location=None, title='Hover over points'\n",
    "    )\n",
    "    p.line(x, y, line_dash=\"4 4\", line_width=1, color='gray')\n",
    "    cr = p.circle(\n",
    "        x, y, size=20, fill_color=\"grey\", alpha=0.1, line_color=None,\n",
    "        hover_fill_color=\"firebrick\", hover_alpha=0.5, hover_line_color=None\n",
    "    )\n",
    "    p.add_tools(HoverTool(tooltips=None, renderers=[cr], mode='hline'))\n",
    "    return p\n",
    "\n",
    "def intro():\n",
    "    return Div(text=\"\"\"\n",
    "        <h3>Welcome to Layout!</h3>\n",
    "        <p>Hopefully you'll see from the code, that the layout tries to get out of your way\n",
    "        and do the right thing. Of course, it might not always, so please report bugs as you\n",
    "        find them and attach them to the epic we're creating <a href=\"\">here</a>.</p>\n",
    "        <p>This is an example of <code>scale_width</code> mode (happy to continue the conversations\n",
    "        about what to name the modes). In <code>scale_width</code> everything responds to the width\n",
    "        that's available to it. Plots alter their height to maintain their aspect ratio, and widgets\n",
    "        are allowed to grow as tall as they need to accomodate themselves. Often times widgets\n",
    "        stay the same height, but text is a good example of a widget that doesn't.</p>\n",
    "        <h4>I want to stress that this was all written in python. There is no templating or\n",
    "        use of <code>bokeh.embed</code>.</h4>\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "l = layout(\n",
    "    [\n",
    "        [intro()],\n",
    "        [text(), scatter()],\n",
    "        [text()],\n",
    "        [hover_plot(), text()],\n",
    "    ],\n",
    "    sizing_mode='scale_width'\n",
    ")\n",
    "\n",
    "show(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
