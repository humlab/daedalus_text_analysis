{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize and Explore a LDA Topic Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Initialize Notebook\n",
    "Import Python libraries and frameworks, and initialize the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"432dd493-4728-43a8-956d-ae759eba8ff1\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"432dd493-4728-43a8-956d-ae759eba8ff1\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"432dd493-4728-43a8-956d-ae759eba8ff1\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '432dd493-4728-43a8-956d-ae759eba8ff1' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"432dd493-4728-43a8-956d-ae759eba8ff1\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"432dd493-4728-43a8-956d-ae759eba8ff1\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"432dd493-4728-43a8-956d-ae759eba8ff1\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '432dd493-4728-43a8-956d-ae759eba8ff1' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"432dd493-4728-43a8-956d-ae759eba8ff1\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import dependencies and setup notebook\n",
    "%run ./common/utility\n",
    "%run ./common/model-utility\n",
    "%run ./common/plot-utility\n",
    "%run ./common/widgets-utility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "import types\n",
    "import ipywidgets as widgets\n",
    "from pivottablejs import pivot_ui\n",
    "\n",
    "from IPython.display import display, clear_output, IFrame\n",
    "from itertools import product\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%autosave 120\n",
    "\n",
    "import bokeh.models as bm\n",
    "import bokeh.palettes\n",
    "\n",
    "from bokeh.io import output_file, show, push_notebook\n",
    "from bokeh.core.properties import value, expr\n",
    "from bokeh.transform import transform, jitter\n",
    "from bokeh.layouts import row, column\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,previewsave\"\n",
    "AGGREGATES = { 'mean': np.mean, 'sum': np.sum, 'max': np.max, 'std': np.std }\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "pd.set_option('precision', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select LDA Model to be Used in Subsequent Plots\n",
    "Select one of the avaliable topic models stored in the ./data directory. New models are made avaliable by uploading them into seperate folders in ./data (for instance using Jupyter Lab). Note that the data must have been prepares with the **compute_lda_model.py** script, and all resulting files must be uploaded.\n",
    "Note that it can take some time (20-30 seconds) to load a model for the first due to large file sizes. Subsequent load is much faster since the system extracts data to CSV-files which gives faster loads.\n",
    "\n",
    "Note! Subsequent cells are NOT updated automatically when a new model is selected.\n",
    "Instead you must use the **play** button, or press **Shift-Enter** to execute the current cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ef89db61f94c07bda9023f522784ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(Dropdown(description='Topic model', layout=Layout(width='75%'), options=('topics_100_NN_PM__no_chunks_iterations_2000_lowercase_ldamodel', 'topics_50_NN_PM__no_chunks_iterations_2000_lowercase_ldamodel', 'topics_150_NN_PM__no_chunks_iterations_2000_lowercase_ldamodel', 'topics_150_NN_PM__no_chunks_iterations_2000_lowercase_ldamallet', 'topics_100_NN_PM__no_chunks_iterations_2000_lowercase_ldamallet', 'topics_50_NN_PM__no_chunks_iterations_2000_lowercase_ldamallet'), value='topics_100_NN_PM__no_chunks_iterations_2000_lowercase_ldamodel'), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Current model state\n",
    "class ModelState:\n",
    "    \n",
    "    def __init__(self, data_folder):\n",
    "        \n",
    "        self.data_folder = data_folder\n",
    "        self.basenames = ModelUtility.get_model_names(data_folder)\n",
    "        self.basename = self.basenames[0]\n",
    "        \n",
    "    def set_model(self, basename=None):\n",
    "\n",
    "        basename = basename or self.basename\n",
    "        \n",
    "        self.basename = basename\n",
    "      \n",
    "        self.document_topic_weights = ModelUtility.\\\n",
    "            get_result_model_sheet(self.data_folder, basename, 'doc_topic_weights')\\\n",
    "            .drop('Unnamed: 0', axis=1)\n",
    "        self.topic_token_weights = ModelUtility\\\n",
    "            .get_result_model_sheet(self.data_folder, basename, 'topic_token_weights')\\\n",
    "            .drop('Unnamed: 0', axis=1)\n",
    "        self.years = [None] + list(range(\n",
    "            self.document_topic_weights.year.min(), self.document_topic_weights.year.max() + 1))\n",
    "        self.n_topics = self.document_topic_weights.topic_id.max() + 1\n",
    "        filename = os.path.join(self.data_folder, basename, 'gensim_model_{}.gensim.gz'.format(basename))\n",
    "        self._lda = None #LdaModel.load(filename)\n",
    "        self.topic_tokens_as_text = None\n",
    "        self.corpus_documents = None\n",
    "        print(\"Current model: \" + self.basename.upper())\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_document_topic_weights(self, year=None, topic_id=None):\n",
    "        df = self.document_topic_weights\n",
    "        if year is None and topic_id is None:\n",
    "            return df\n",
    "        if topic_id is None:\n",
    "            return df[(df.year == year)]\n",
    "        if year is None:\n",
    "            return df[(df.topic_id == topic_id)]\n",
    "        return df[(df.year == year)&(df.topic_id == topic_id)]\n",
    "    \n",
    "    def get_unique_topic_ids(self):\n",
    "        return self.document_topic_weights['topic_id'].unique()\n",
    "    \n",
    "    def get_topic_weight_by_year_or_document(self, key='mean', year=None):\n",
    "        pivot_column = 'year' if year is None else 'document_id'    \n",
    "        df = self.get_document_topic_weights(year) \\\n",
    "            .groupby([pivot_column,'topic_id']) \\\n",
    "            .agg(AGGREGATES[key])[['weight']].reset_index()\n",
    "        return df, pivot_column\n",
    "\n",
    "    def get_lda(self):\n",
    "        if self._lda is None:\n",
    "            filename = 'gensim_model_{}.gensim.gz'.format(self.basename)\n",
    "            self._lda = LdaModel.load(os.path.join(self.data_folder, self.basename, filename))\n",
    "            print('LDA model loaded...')\n",
    "        return self._lda \n",
    "    \n",
    "    def get_topics_tokens_as_text(self, n_words=100, cache=True):\n",
    "        if cache and self.topic_tokens_as_text is not None:\n",
    "            return self.topic_tokens_as_text\n",
    "        topic_tokens_as_text = ModelUtility.get_topics_tokens_as_text(state.topic_token_weights, n_words=n_words)\n",
    "        if cache:\n",
    "            self.topic_tokens_as_text = topic_tokens_as_text\n",
    "        return topic_tokens_as_text\n",
    "    \n",
    "    def get_topic_tokens(self, topic_id, max_n_words=500):\n",
    "        tokens = state.topic_token_weights\\\n",
    "            .loc[lambda x: x.topic_id == topic_id]\\\n",
    "            .sort_values('weight',ascending=False)[:max_n_words]\n",
    "        return tokens\n",
    "\n",
    "    def get_topic_year_aggregate_weights(self, fn, threshold):\n",
    "        df = self.document_topic_weights\n",
    "        #df = df[(df.weight>=threshold)]\n",
    "        df = df.groupby(['year', 'topic_id']).agg(fn)['weight'].reset_index()\n",
    "        df = df[(df.weight>=threshold)]\n",
    "        return df\n",
    "    \n",
    "    def get_topic_proportions(self):\n",
    "        corpus_documents = self.get_corpus_documents()\n",
    "        document_topic_weights = self.get_document_topic_weights()\n",
    "        topic_proportion = ModelUtility.compute_topic_proportions(document_topic_weights, corpus_documents)\n",
    "        return topic_proportion\n",
    "    \n",
    "    def get_corpus_documents(self):\n",
    "        if self.corpus_documents is None:\n",
    "            self.corpus_documents = ModelUtility.get_corpus_documents(self.data_folder, self.basename)\n",
    "        return self.corpus_documents\n",
    "\n",
    "state = ModelState('./tm-data')\n",
    "\n",
    "wdg_basename = widgets.Dropdown(\n",
    "    options=state.basenames,\n",
    "    value=state.basename,\n",
    "    description='Topic model',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='75%')\n",
    ")\n",
    "wdg_model = widgets.interactive(state.set_model, basename=wdg_basename)\n",
    "display(widgets.VBox((wdg_basename,) + (wdg_model.children[-1],)))\n",
    "wdg_model.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents' Topic-Weight Distribution\n",
    "This graph displays the distribution of document topic-weights for the selected model. The X-axis percentage i.e. a value between 0 and 100, and the Y-axis is the number of document topic-weights for each (integer) percentage.\n",
    "Noteworthy is that the vast majority (97-98) %of the weights are zero, or close to zero. On the other end of the graph, a large share of the remaining weight with a significant weight have a very high weight (above 90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf3fb25080f4924938324240ee4b8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(SelectionRangeSlider(description='Interval', index=(0, 99), options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99), value=(0, 99)), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Topic Weight Distribution\n",
    "topic_weights_distribution = state.get_document_topic_weights()\n",
    "topic_weights_distribution['weight%'] = (topic_weights_distribution.weight * 100).astype('int')\n",
    "topic_weights_distribution = topic_weights_distribution.groupby('weight%').size()\n",
    "topic_weights_count = topic_weights_distribution.sum()\n",
    "\n",
    "def display_topic_weights_distribution(p_range):\n",
    "    global topic_weights_distribution\n",
    "    selection = topic_weights_distribution[p_range[0]:p_range[1]+1]\n",
    "    title = '{0:.2f}% of all document-topic weights are within selected interval'\\\n",
    "          .format(100 * (selection.sum() / topic_weights_count))\n",
    "    selection.plot(figsize=(12,6), title=title, kind='line', xlim=(0,100))\n",
    "\n",
    "p_range = widgets.SelectionRangeSlider(\n",
    "    options=range(0,100), index=(0,99), description='Interval', continues_update=False\n",
    ")\n",
    "\n",
    "w = widgets.interactive(display_topic_weights_distribution, p_range=p_range)\n",
    "display(widgets.VBox(\n",
    "    (p_range,) +\n",
    "    (w.children[-1],)))\n",
    "w.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Topic Wordclouds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b69568f3c2d4c6f837313b35c280a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='wc01'/>\", placeholder=''), HBox(children=(Button(description='<<', style=ButtonStyle(button_color='lightgreen')), Button(description='>>', style=ButtonStyle(button_color='lightgreen')), IntSlider(value=0, continuous_update=False, description='Topic ID', max=99), IntSlider(value=50, continuous_update=False, description='Word count', max=500, min=1))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Not found\n"
     ]
    }
   ],
   "source": [
    "# Display LDA topic's token wordcloud\n",
    "%run ./common/widgets-utility\n",
    "opts = { 'max_font_size': 100, 'background_color': 'white', 'width': 800, 'height': 800 }\n",
    "\n",
    "z = BaseWidgetUtility(\n",
    "    n_topics=state.n_topics,\n",
    "    text_id='wc01',\n",
    "    text=wf.create_text_widget('wc01'),\n",
    "    topic_id=wf.topic_id_slider(state.n_topics),\n",
    "    word_count=wf.word_count_slider(1, 500),\n",
    "    prev_topic_id=wf.create_prev_id_button('topic_id', state.n_topics),\n",
    "    next_topic_id=wf.create_next_id_button('topic_id', state.n_topics)\n",
    ")\n",
    "\n",
    "#z = TopicWidgets(state.n_topics, years=None, word_count=True)\n",
    "\n",
    "def display_wordcloud(topic_id=0, n_words=100):\n",
    "    global state\n",
    "    df_temp = state.topic_token_weights\n",
    "    tokens = state.get_topics_tokens_as_text(n_words=n_words, cache=True).iloc[topic_id]\n",
    "    z.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "    WordcloudUtility.plot_wordcloud(df_temp, 'token', 'weight', max_words=n_words, **opts)\n",
    "\n",
    "iw = widgets.interactive(display_wordcloud, topic_id=z.topic_id, n_words=z.word_count)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (z.text,) +\n",
    "    (widgets.HBox((z.prev_topic_id,) +(z.next_topic_id,) + (z.topic_id,) + (z.word_count,)),) +\n",
    "    (iw.children[-1],)))\n",
    "iw.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ebf3e30763443ca23fdb16c3f3f0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value='', placeholder=''), HBox(children=(Button(description='<<', style=ButtonStyle(button_color='lightgreen')), Button(description='>>', style=ButtonStyle(button_color='lightgreen')), IntSlider(value=0, continuous_update=False, description='Topic ID', max=99), IntSlider(value=200, continuous_update=False, description='Word count', max=500, min=1))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display LDA topic's token wordcloud\n",
    "\n",
    "def plot_tokens(tokens, **args):\n",
    "    \n",
    "    source = ColumnDataSource(tokens)\n",
    "    \n",
    "    p = figure(toolbar_location=\"right\", **args)\n",
    "\n",
    "    cr = p.circle(x='xs', y='ys', source=source)\n",
    "\n",
    "    label_style = dict(level='overlay', text_font_size='8pt', angle=np.pi/6.0)\n",
    "    \n",
    "    text_aligns = ['left', 'right']\n",
    "    for i in [0, 1]:\n",
    "        label_source = ColumnDataSource(tokens.iloc[i::2])\n",
    "        labels = bm.LabelSet(x='xs', y='ys', text_align=text_aligns[i], text='token', text_baseline='middle',\n",
    "                          y_offset=5*(1 if i == 0 else -1),\n",
    "                          x_offset=5*(1 if i == 0 else -1),\n",
    "                          source=label_source, **label_style)\n",
    "        p.add_layout(labels)\n",
    "    \n",
    "    p.xaxis[0].axis_label = 'Token #'\n",
    "    p.yaxis[0].axis_label = 'Weight'\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"6pt\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    return p\n",
    "\n",
    "    \n",
    "def display_topic_tokens(topic_id=0, n_words=100):\n",
    "    global state\n",
    "    tokens = state.get_topic_tokens(topic_id=topic_id).\\\n",
    "        copy()\\\n",
    "        .drop('topic_id', axis=1)\\\n",
    "        .assign(weight=lambda x: 100.0 * x.weight).head(n_words)\n",
    "        \n",
    "    tokens = tokens.assign(xs=tokens.index, ys=tokens.weight)\n",
    "    \n",
    "    #print(tokens.weight.sum())\n",
    "    #print(tokens.head(n_words))\n",
    "    #return\n",
    "    left = plot_tokens(tokens, plot_width=450, plot_height=500, title='', tools='box_zoom,wheel_zoom,pan,reset')\n",
    "    right = plot_tokens(tokens, plot_width=450, plot_height=500, title='', tools='pan')\n",
    "\n",
    "    source = ColumnDataSource({'x':[], 'y':[], 'width':[], 'height':[]})\n",
    "    left.x_range.callback = create_js_callback('x', 'width', source)\n",
    "    left.y_range.callback = create_js_callback('y', 'height', source)\n",
    "\n",
    "    rect = bm.Rect(x='x', y='y', width='width', height='height', fill_alpha=0.0, line_color='blue', line_alpha=0.4)\n",
    "    right.add_glyph(source, rect)\n",
    "\n",
    "    show(row(left, right))\n",
    "\n",
    "z = TopicWidgets(state.n_topics, years=None, word_count=True)\n",
    "z.word_count.value = 200\n",
    "w = widgets.interactive(display_topic_tokens, topic_id=z.topic_id, n_words=z.word_count)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (z.text,) +\n",
    "    (widgets.HBox((z.prev_topic_id,) +(z.next_topic_id,) + (z.topic_id,) + (z.word_count,)),) +\n",
    "    (w.children[-1],)))\n",
    "\n",
    "w.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plot Topic's Weight Over Time\n",
    "Display a specific topics share over time as well as listing topic terms in descending order (based on yearly mean weight over all documents). The *whisker* displays max and mean topic weight for given year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967265e3bbf14eb4a19108847053e326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value='', placeholder=''), HBox(children=(Button(description='<<', style=ButtonStyle(button_color='lightgreen')), Button(description='>>', style=ButtonStyle(button_color='lightgreen')), IntSlider(value=0, continuous_update=False, description='Topic ID', max=99), Dropdown(description='Year', options=(None, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014), value=None), Dropdown(description='Aggregate', options=('mean', 'max', 'std'), value='mean'))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a topic's yearly weight over time in selected LDA topic model\n",
    "\n",
    "def plot_topic_over_time(df, pivot_column, value_column, topic_id=0, year=None, whisker=False):\n",
    "\n",
    "    source = ColumnDataSource(df)\n",
    "    p = figure(plot_width=900, plot_height=600, title='', tools=TOOLS, toolbar_location=\"right\")\n",
    "    p.xaxis[0].axis_label = pivot_column.title()\n",
    "    p.yaxis[0].axis_label = value_column.title() + ('weight' if value_column != 'weight' else '')\n",
    "    p.y_range.start = 0.0\n",
    "    p.y_range.end = 1.0\n",
    "\n",
    "    day_width = 60*60*24*1000\n",
    "    glyph = bm.glyphs.VBar(x=pivot_column, top=value_column, bottom=0, width=1, fill_color=\"#b3de69\")\n",
    "    p.add_glyph(source, glyph)\n",
    "    if whisker and year is None:\n",
    "        p.add_layout(\n",
    "            bm.Whisker(source=source, base=pivot_column, upper=\"max\", lower=value_column)\n",
    "        )\n",
    "    #if not year is None: print(df_temp[['index', 'document', 'topic_id', 'weight']])\n",
    "    return p\n",
    "\n",
    "def display_topic_over_time(topic_id, year, value_column):\n",
    "    global state\n",
    "\n",
    "    tokens = state.get_topics_tokens_as_text(n_words=200, cache=True).iloc[topic_id]\n",
    "    z.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "\n",
    "    pivot_column = 'year' if year is None else 'document_id'\n",
    "    value_column = value_column if year is None else 'weight'\n",
    "    \n",
    "    df = state.document_topic_weights[(state.document_topic_weights.topic_id==topic_id)]\n",
    "    \n",
    "    if year is None:\n",
    "        df = df.groupby([pivot_column, 'topic_id']).agg([np.mean, np.max, np.std])['weight'].reset_index()\n",
    "        df.columns = ['year', 'topic_id', 'mean', 'max', 'std']\n",
    "    else:\n",
    "        df = df[(df.year==year)]\n",
    "        \n",
    "    p = plot_topic_over_time(df, pivot_column, value_column, topic_id, year,  False)\n",
    "    show(p)\n",
    "    \n",
    "z = TopicWidgets(state.n_topics, state.years)\n",
    "z.aggregate = z.create_select_widget('Aggregate', ['mean', 'max', 'std'], default='mean')\n",
    "w = widgets.interactive(display_topic_over_time, topic_id=z.topic_id, year=z.year, value_column=z.aggregate)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (z.text,) + \n",
    "    (widgets.HBox((z.prev_topic_id,) + (z.next_topic_id,) + (z.topic_id,) + (z.year,) + (z.aggregate,)),) + \n",
    "    (w.children[-1],)))\n",
    "w.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Stacked Bar of Most Relevant Topics\n",
    "Display topic shares in descending order as a stacked bar chart. Order is based on selected aggregate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33763b6a8e34874a9546dcd3e01df20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='topic_share_plot'/>\", placeholder=''), HBox(children=(Dropdown(description='Aggregate', index=2, options=('max', 'sum', 'mean', 'std'), value='mean'), IntSlider(value=3, continuous_update=False, description='Topic count', max=99), Dropdown(description='Year', options=(None, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014), value=None))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot topic shares (year aggregate or per document for selected year)\n",
    "\n",
    "def prepare_stacked_topic_share_data(key, n_topics, year):\n",
    "    global state\n",
    "    pivot_column = 'year' if year is None else 'document_id'\n",
    "    \n",
    "    df_data = state.get_document_topic_weights(year)\n",
    "\n",
    "    df = ModelUtility.get_document_topic_weights_pivot(df_data, AGGREGATES[key], pivot_column)\n",
    "    df.set_index(pivot_column, inplace=True)\n",
    "    \n",
    "    n_topics = min(len(df.columns), n_topics)\n",
    "    topic_toplist = df[df.columns].sum().sort_values(axis=0, ascending=False)\n",
    "    df_top = df[topic_toplist[:n_topics].index].copy()\n",
    "\n",
    "    df = df_top.reset_index()\n",
    "    df.columns = [ str(x) for x in  df.columns ]\n",
    "    \n",
    "    return df, pivot_column, n_topics\n",
    "\n",
    "def generate_category_colors(n_items, palette=bokeh.palettes.Category20[20]):\n",
    "    ''' Repeat palette to get n_items colors '''\n",
    "    colors = (((n_items // len(palette)) + 1) * palette)[:n_items]\n",
    "    return colors\n",
    "\n",
    "def plot_stacked_bar_of_topic_over_time(df, pivot_column, key='mean', n_topics=3, year=None, n_words=100):\n",
    "    \n",
    "    categories = list(df.columns[1:])\n",
    "    colors = generate_category_colors(n_topics)\n",
    "    source = ColumnDataSource(df)\n",
    "    \n",
    "    p = figure(plot_width=900, plot_height=800, title=state.basename, tools=TOOLS, toolbar_location=\"right\")\n",
    "    \n",
    "    p.xaxis[0].axis_label = key.title() + ' weight'\n",
    "    p.yaxis[0].axis_label = pivot_column.title()\n",
    "    \n",
    "    #legend = [ value(x) for x in categories ]\n",
    "    #p.hbar_stack(categories, y=pivot_column, source=source, color=colors, height=0.5, legend=legend)\n",
    "        \n",
    "    bottoms, tops = [], []\n",
    "    for i, category in enumerate(categories):\n",
    "        tops = tops + [category]\n",
    "        cr = p.hbar(y=pivot_column,\n",
    "                    left=expr(bm.expressions.Stack(fields=bottoms)),\n",
    "                    right=expr(bm.expressions.Stack(fields=tops)),\n",
    "                    color=colors[i],\n",
    "                    height=0.5,\n",
    "                    source=source,\n",
    "                    legend='Topic ' + str(category))\n",
    "        topic_id = int(category)\n",
    "        tooltip = 'ID {}: {}'.format(topic_id, state.get_topics_tokens_as_text(n_words=200, cache=True).iloc[topic_id])\n",
    "        p.add_tools(bm.HoverTool(tooltips=tooltip, renderers=[cr]))\n",
    "        bottoms = bottoms + [category]\n",
    "            \n",
    "    return p\n",
    "\n",
    "def display_stacked_bar_of_topic_over_time(key='mean', n_topics=3, year=None):\n",
    "    \n",
    "    global state\n",
    "    \n",
    "    ''' Prepare the plot data '''\n",
    "    \n",
    "    df, pivot_column, n_topics = prepare_stacked_topic_share_data(key, n_topics, year)\n",
    "    \n",
    "    p = plot_stacked_bar_of_topic_over_time(df, pivot_column, key, n_topics, year)\n",
    "    show(p)\n",
    "    \n",
    "z = TopTopicWidgets(state.n_topics, state.years, aggregates=list(AGGREGATES.keys()), text_id='topic_share_plot')\n",
    "w = widgets.interactive(display_stacked_bar_of_topic_over_time, n_topics=z.topics_count,  key=z.aggregate, year=z.year)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (z.text,) + \n",
    "    (widgets.HBox((z.aggregate,) + (z.topics_count,) + (z.year,)),) + \n",
    "    (w.children[-1],)))\n",
    "\n",
    "w.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Document-Topic Weights\n",
    "List aggregated topic weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca86cca07ea04bc5a77f0c66a3cac25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='text_id'/>\", placeholder=''), HBox(children=(Dropdown(description='Aggregate', index=2, options=('max', 'sum', 'mean', 'std'), value='mean'), Dropdown(description='Year', options=(None, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014), value=None))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Folded code\n",
    "import IPython.display # import display, HTML\n",
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "def plot_stacked_bar_of_topic_over_time(key='mean', year=None):\n",
    "    global state\n",
    "    pivot_column = 'year' if year is None else 'document_id'   \n",
    "    df_data = state.get_document_topic_weights(year)\n",
    "    df_temp = ModelUtility.get_document_topic_weights_pivot(df_data, AGGREGATES[key], pivot_column)\n",
    "    df_temp.set_index(pivot_column, inplace=True)\n",
    "    IPython.display.display(df_temp.head(5))\n",
    "    \n",
    "z = TopTopicWidgets(state.n_topics, state.years, aggregates=list(AGGREGATES.keys()))\n",
    "w = widgets.interactive(plot_stacked_bar_of_topic_over_time, key=z.aggregate, year=z.year)\n",
    "\n",
    "display(widgets.VBox((z.text,) +  (widgets.HBox((z.aggregate,) + (z.year,)),) +  (w.children[-1],)))\n",
    "w.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot (or heatmap) of topic shares per year or document\n",
    "Display topic shares as a scatter plot using gradient color for topic's weight.\n",
    "FIXME: Display only every 10th tick marker\n",
    "FIXME: Display words when hover is on y-axis instead (higlight entire row)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1387c8672cf944158da545258df87781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Aggregate', index=2, options=('max', 'sum', 'mean', 'std'), value='mean'), Dropdown(description='Glyph', options=('Circle', 'Square'), value='Circle'), Dropdown(description='Year', options=(None, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014), value=None))), HTML(value=\"<span class='topic_relevance'/>\", placeholder=''), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_topic_relevance_by_year\n",
    "\n",
    "def setup_glyph_coloring(df):\n",
    "    max_weight = df.weight.max()\n",
    "    #colors = list(reversed(bokeh.palettes.Greens[9]))\n",
    "    colors = [\"#efefef\", \"#75968f\", \"#a5bab7\", \"#c9d9d3\", \"#e2e2e2\", \"#dfccce\", \"#ddb7b1\", \"#cc7878\",\n",
    "              \"#933b41\", \"#550b1d\"]\n",
    "    mapper = bm.LinearColorMapper(palette=colors, low=df.weight.min(), high=max_weight)\n",
    "    color_transform = transform('weight', mapper)\n",
    "    color_bar = bm.ColorBar(color_mapper=mapper, location=(0, 0),\n",
    "                         ticker=bm.BasicTicker(desired_num_ticks=len(colors)),\n",
    "                         formatter=bm.PrintfTickFormatter(format=\" %5.2f\"))\n",
    "    return color_transform, color_bar\n",
    "\n",
    "def plot_topic_relevance_by_year(df, xs, ys, glyph, titles, text_id):\n",
    "\n",
    "    ''' Setup axis categories '''\n",
    "    x_range = list(map(str, df[xs].unique()))\n",
    "    y_range = list(map(str, df[ys].unique()))\n",
    "    \n",
    "    ''' Setup coloring and color bar '''\n",
    "    color_transform, color_bar = setup_glyph_coloring(df)\n",
    "    \n",
    "    source = ColumnDataSource(df)\n",
    "\n",
    "    p = figure(title=\"Topic heatmap\", toolbar_location=None, tools=\"\", x_range=x_range,\n",
    "           y_range=y_range, x_axis_location=\"above\", plot_width=900, plot_height=900)\n",
    "\n",
    "    args = dict(x=xs, y=ys, source=source, alpha=1.0, hover_color='red')\n",
    "    \n",
    "    if glyph == 'Circle':\n",
    "        cr = p.circle(color=color_transform, **args)\n",
    "    else:\n",
    "        cr = p.rect(width=1, height=1, line_color=None, fill_color=color_transform, **args)\n",
    "\n",
    "    p.x_range.range_padding = 0\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"5pt\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    p.xaxis.major_label_orientation = 1.0\n",
    "    p.add_layout(color_bar, 'right')\n",
    "    \n",
    "    p.add_tools(bm.HoverTool(tooltips=None, callback=WidgetUtility.glyph_hover_callback(\n",
    "        source, 'topic_id', titles.index, titles, text_id), renderers=[cr]))\n",
    "    \n",
    "    return p\n",
    "    \n",
    "def display_topic_relevance_by_year(key='mean', year=None, glyph='Circle'):\n",
    "    global state\n",
    "    titles = ModelUtility.get_topic_titles(state.topic_token_weights, n_words=100)\n",
    "    df, pivot_column = state.get_topic_weight_by_year_or_document(key=key, year=year)\n",
    "    df[pivot_column] = df[pivot_column].astype(str)\n",
    "    df['topic_id'] = df.topic_id.astype(str)\n",
    "    p = plot_topic_relevance_by_year(df, xs=pivot_column, ys='topic_id', glyph=glyph,\n",
    "                                     titles=titles, text_id='topic_relevance')\n",
    "    show(p)\n",
    "    \n",
    "u = TopTopicWidgets(0, state.years, aggregates=list(AGGREGATES.keys()), text_id='topic_relevance')\n",
    "u.glyph = widgets.Dropdown(options=['Circle', 'Square'], value='Circle', description='Glyph', disabled=False)\n",
    "\n",
    "w = widgets.interactive(display_topic_relevance_by_year, key=u.aggregate, year=u.year, glyph=u.glyph)\n",
    "\n",
    "display(widgets.VBox((widgets.HBox((u.aggregate,) + (u.glyph,) + (u.year,)),) + (u.text,) + (w.children[-1],)))\n",
    "        \n",
    "w.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Classes for Network Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%run ./common/network-utility\n",
    "%run ./common/vectorspace-utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([5,4,3,2,1])[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plot Topic-to-Year Associations as a Network Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2641172c95d492e96b852432d8592ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='nx_id1'/>\", placeholder=''), HBox(children=(Dropdown(description='Layout', options=('Fruchterman-Reingold', 'Circular', 'Shell', 'Kamada-Kawai', 'Eigenvectors of Laplacian'), value='Fruchterman-Reingold'), Dropdown(description='Aggregate', index=2, options=('max', 'sum', 'mean', 'std'), value='mean'))), HBox(children=(FloatSlider(value=0.0, continuous_update=False, description='Threshold', max=1.0, step=0.01), FloatSlider(value=0.1, continuous_update=False, description='Scale', max=1.0, step=0.01))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize year-to-topic correlations by means of topic-document-weight dimensional reduction\n",
    "#setup_glyph_id_text_hover_callback(topic_nodes_source, ids=titles.index, text=titles, element_id='nx_id1')\n",
    "     \n",
    "def plot_topic_year_network(network, layout, scale=1.0, titles=None):\n",
    "\n",
    "    year_nodes, topic_nodes = NetworkUtility.get_bipartite_node_set(network, bipartite=0)  \n",
    "    \n",
    "    year_source = NetworkUtility.get_node_subset_source(network, layout, year_nodes)\n",
    "    topic_source = NetworkUtility.get_node_subset_source(network, layout, topic_nodes)\n",
    "    lines_source = NetworkUtility.get_edges_source(network, layout, scale=6.0, normalize=False)\n",
    "    \n",
    "    edges_alphas = NetworkMetricHelper.compute_alpha_vector(lines_source.data['weights'])\n",
    "    \n",
    "    lines_source.add(edges_alphas, 'alphas')\n",
    "    \n",
    "    p = figure(plot_width=900, plot_height=900, x_axis_type=None, y_axis_type=None, tools=TOOLS)\n",
    "    \n",
    "    r_lines = p.multi_line('xs', 'ys', line_width='weights', alpha='alphas', color='black', source=lines_source)\n",
    "    r_years = p.circle('x','y', size=40, source=year_source, color='olive', level='overlay', line_width=1,alpha=0.9)\n",
    "    r_topics = p.circle('x','y', size=25, source=topic_source, color='skyblue', level='overlay', alpha=0.90)\n",
    "    \n",
    "    p.add_tools(bm.HoverTool(renderers=[r_topics], tooltips=None, callback=WidgetUtility.\\\n",
    "        glyph_hover_callback(topic_source, 'node_id', text_ids=titles.index, text=titles, element_id='nx_id1'))\n",
    "    )\n",
    "\n",
    "    text_opts = dict(x='x', y='y', text='name', level='overlay', text_align='center', text_baseline='middle',\n",
    "                      x_offset=0, y_offset=0, text_font='Arial', text_font_size='8pt')\n",
    "    \n",
    "    p.add_layout(bm.LabelSet(source=year_source, text_color='black', **text_opts))\n",
    "    p.add_layout(bm.LabelSet(source=topic_source,  text_color='black', **text_opts))\n",
    "    \n",
    "    #selected_circle = Circle(fill_alpha=1, fill_color=\"olive\", line_color=None)\n",
    "    #nonselected_circle = Circle(fill_alpha=0.2, fill_color=\"blue\", line_color=\"firebrick\")\n",
    "    #r_topics.selection_glyph = selected_circle\n",
    "    #r_topics.nonselection_glyph = nonselected_circle\n",
    "    \n",
    "    return p\n",
    "    \n",
    "def display_topic_year_network(layout_algorithm, aggregate='mean', threshold=0.10, scale=1.0):\n",
    "    global state\n",
    "                                       \n",
    "    titles = state.get_topics_tokens_as_text()\n",
    "    df = state.get_topic_year_aggregate_weights(AGGREGATES[aggregate], threshold)\n",
    "    \n",
    "    #print(df_temp)\n",
    "    #return\n",
    "    \n",
    "    network = NetworkUtility.create_bipartite_network(df, 'year', 'topic_id')\n",
    "\n",
    "    args = NetworkUtility.layout_args(layout_algorithm, network, scale)\n",
    "    layout = (layout_algorithms[layout_algorithm])(network, **args)\n",
    "        \n",
    "    p = plot_topic_year_network(network, layout, scale=scale, titles=titles)\n",
    "    \n",
    "    show(p)\n",
    "\n",
    "u = TopTopicWidgets(text_id='nx_id1', aggregates=list(AGGREGATES.keys()), \n",
    "                    layout_algorithms=list(layout_algorithms.keys()))\n",
    "u.scale = u.create_float_slider('Scale', min=0.0, max=1.0, step=0.01, value=0.1)\n",
    "u.threshold = u.create_float_slider('Threshold', min=0.0, max=1.0, step=0.01, value=0.0)\n",
    "w = widgets.interactive(display_topic_year_network, layout_algorithm=u.layout_algorithm,\n",
    "                        aggregate=u.aggregate, threshold=u.threshold, scale=u.scale)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (u.text, ) +\n",
    "    (widgets.HBox((u.layout_algorithm, ) + (u.aggregate,)),) +\n",
    "    (widgets.HBox((u.threshold,) + (u.scale,)),) +\n",
    "    (w.children[-1],)))\n",
    "\n",
    "w.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Similarity Network\n",
    "This plot displays topic similarity based on **euclidean or cosine distances** between the **topic-to-word vectors**. Please note that the computations can take some time to exceute, especially for larger LDA models.\n",
    "\n",
    "1. Compute a multi dimensional topic vector space based on the top n words for each topic. Since the subset of words differs, and their positions differs between topics they need to be aligned in common space so that 1) each vector has the same dimension (i.e. number of unique top n tokens over all topics) and 2) each token has the same position within that space. (using sklearn DictVectorizer). The vector space will have as many dimensions as the number of unique top n words over all topics.\n",
    "2. Reduce the topic vector space into a 2D space (using sklearn PCA)\n",
    "3. Normalize the 2D space (sklearn Normalizer)\n",
    "\n",
    "TODO: DONE Use cosine similarity as alternativ to spatial distance\n",
    "TODO: Alternative to use 1) DONE topic-term vector space 2) DONE PCA nD 3) T-SNE\n",
    "TODO: Save network to file (either via pandas or networkx)\n",
    "TODO: Should partition/community be computed before or after network is filtered?\n",
    "\n",
    "Note: Steps 1 to 3 above (the most time consuming) are executed whenever an option marked with an asterix is changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# plot_correlation_network\n",
    "\n",
    "DFLT_NODE_OPTS = dict(color='green', level='overlay', alpha=1.0)\n",
    "DFLT_EDGE_OPTS = dict(color='black', alpha=0.2)\n",
    "\n",
    "def plot_correlation_network(\n",
    "    network,\n",
    "    layout_algorithm=None,\n",
    "    scale=1.0,\n",
    "    threshold=0.0,\n",
    "    node_description=None,\n",
    "    node_proportions=None,\n",
    "    weight_scale=5.0,\n",
    "    normalize_weights=True,\n",
    "    node_opts=None,\n",
    "    line_opts=None\n",
    "):\n",
    "    if threshold > 0:\n",
    "        max_weight = max(nx.get_edge_attributes(network, 'weight').values())\n",
    "        filter_edges = [(u, v) for u, v, d in network.edges(data=True) if d['weight'] >= (threshold * max_weight)]\n",
    "        sub_network = network.edge_subgraph(filter_edges)\n",
    "    else:\n",
    "        sub_network = network\n",
    "        \n",
    "    args = NetworkUtility.layout_args(layout_algorithm, sub_network, scale)\n",
    "    layout = (layout_algorithms[layout_algorithm])(sub_network, **args)\n",
    "\n",
    "    lines_source = NetworkUtility.get_edges_source(\n",
    "        sub_network, layout, scale=weight_scale, normalize=normalize_weights\n",
    "    )\n",
    "    nodes_source = NetworkUtility.create_nodes_data_source(sub_network, layout)\n",
    "\n",
    "    nodes_community = NetworkMetricHelper.compute_partition(sub_network)\n",
    "    community_colors = NetworkMetricHelper.partition_colors(nodes_community, bokeh.palettes.Category20[20])\n",
    "    \n",
    "    nodes_source.add(nodes_community, 'community')\n",
    "    nodes_source.add(community_colors, 'community_color')\n",
    "    \n",
    "    nodes_size = 5\n",
    "    if node_proportions is not None:\n",
    "        # NOTE!!! By pd index - not iloc!!\n",
    "        nodes_weight = 2000 * node_proportions.loc[list(sub_network.nodes)]\n",
    "        nodes_size = 'size'\n",
    "        nodes_source.add(nodes_weight, nodes_size)\n",
    "\n",
    "    node_opts = extend(DFLT_NODE_OPTS, node_opts or {})\n",
    "    line_opts = extend(DFLT_EDGE_OPTS, line_opts or {})\n",
    "    \n",
    "    p = figure(plot_width=900, plot_height=900, x_axis_type=None, y_axis_type=None) #, tools=tools)\n",
    "    #node_size = 'size' if node_proportions is not None else 5\n",
    "    r_lines = p.multi_line('xs', 'ys', line_width='weights', source=lines_source, **line_opts)\n",
    "    r_nodes = p.circle('x', 'y', size=nodes_size, source=nodes_source, **node_opts)\n",
    "    \n",
    "    p.add_tools(bm.HoverTool(renderers=[r_nodes], tooltips=None, callback=WidgetUtility.\\\n",
    "        glyph_hover_callback(nodes_source, 'node_id', text_ids=node_description.index, \\\n",
    "                             text=node_description, element_id='nx_id3'))\n",
    "    )\n",
    "    \n",
    "    text_opts = dict(x='x', y='y', text='name', level='overlay', text_align='center', text_baseline='middle',\n",
    "                      x_offset=0, y_offset=0,text_font='Arial')\n",
    "\n",
    "    r_nodes.glyph.fill_color = 'community_color'\n",
    "\n",
    "    p.add_layout(bm.LabelSet(source=nodes_source, text_color='black', **text_opts))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     14
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0f3d0b7cdf487e9f442e024c9a8b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='nx_id3'/>\", placeholder=''), HBox(children=(FloatSlider(value=0.1, continuous_update=False, description='Threshold', max=1.0, step=0.01), Dropdown(description='Reducer*', index=1, options=('passthrough', 'pca', 'pca_norm', 'tsne'), value='pca'), Dropdown(description='Metric*', options=('Cosine', 'Correlation', 'Normalized Euclidean', 'Squared Euclidean', 'Euclidean'), value='Cosine'))), HBox(children=(IntSlider(value=200, continuous_update=False, description='#words*', max=500, min=10), Dropdown(description='Layout', index=1, options=('Circular', 'Fruchterman-Reingold', 'Kamada-Kawai', 'Shell', 'Eigenvectors of Laplacian'), value='Fruchterman-Reingold'), FloatSlider(value=0.1, continuous_update=False, description='Scale', max=1.0, step=0.01))), IntProgress(value=0, max=10), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization\n",
    "if 'nx_data' not in globals():\n",
    "    nx_data = types.SimpleNamespace(\n",
    "        network=None,\n",
    "        X_n_space=None,\n",
    "        X_pca_norm=None,\n",
    "        X_tsne_norm=None,\n",
    "        distance_matrix=None,\n",
    "        metric=None,\n",
    "        reducer=None,\n",
    "        topic_proportions=None,\n",
    "        n_words = 0\n",
    "    )\n",
    "\n",
    "def plot_clustering_dendogram(clustering):\n",
    "    plt.figure(figsize=(16,6))\n",
    "    # https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n",
    "    R = dendrogram(clustering)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def display_correlation_network(\n",
    "    layout_algorithm, threshold=0.10, scale=1.0, metric='Euclidean', reducer='tsne', n_words=200):\n",
    "    global state, data, u\n",
    "\n",
    "    u.progress.value = 1\n",
    "    metric = DISTANCE_METRICS[metric]\n",
    "    n_components = 3 if reducer == 'tsne' else 20\n",
    "    perplexity=30\n",
    "    \n",
    "    node_description = state.get_topics_tokens_as_text()\n",
    "    node_proportions = state.get_topic_proportions()\n",
    "    #print(df_temp)\n",
    "    #return\n",
    "    u.progress.value = 2\n",
    "    if nx_data.network is None or nx_data.metric != metric or nx_data.reducer != reducer or nx_data.n_words != n_words:\n",
    "        nx_data.n_words = n_words\n",
    "        nx_data.metric, nx_data.reducer = metric, reducer\n",
    "        nx_data.pca_norm = None\n",
    "        nx_data.X_n_space, _ = ModelUtility.compute_topic_terms_vector_space(state.get_lda(), n_words=n_words)\n",
    "        u.progress.value = 3\n",
    "        nx_data.X_m_space = VectorSpaceHelper.\\\n",
    "                reduce_dimensions(nx_data.X_n_space, method=reducer, n_components=n_components, perplexity=perplexity)\n",
    "            \n",
    "        u.progress.value = 5\n",
    "        nx_data.distance_matrix = VectorSpaceHelper.compute_distance_matrix(nx_data.X_m_space, metric=metric)\n",
    "        u.progress.value = 7\n",
    "        nx_data.network = NetworkUtility.create_network_from_correlation_matrix(nx_data.distance_matrix)\n",
    "\n",
    "    u.progress.value = 8\n",
    "    p = plot_correlation_network(network=nx_data.network,\n",
    "                             layout_algorithm=layout_algorithm,\n",
    "                             scale=scale, threshold=threshold,\n",
    "                             node_description=node_description,\n",
    "                             node_proportions=node_proportions)\n",
    "    \n",
    "    u.progress.value = 10\n",
    "    show(p)\n",
    "    u.progress.value = 0\n",
    "    \n",
    "u = TopTopicWidgets(text_id='nx_id3', layout_algorithms=list(layout_algorithms.keys()))\n",
    "\n",
    "u.scale = u.create_float_slider('Scale', min=0.0, max=1.0, step=0.01, value=0.1)\n",
    "u.progress = u.create_int_progress_widget(min=0, max=10, step=2, value=0)\n",
    "u.threshold = u.create_float_slider('Threshold', min=0.0, max=1.0, step=0.01, value=0.10)\n",
    "u.metric = u.create_select_widget(label='Metric*', values=list(DISTANCE_METRICS.keys()), default='Cosine')\n",
    "u.reducer = u.create_select_widget(label='Reducer*', values=['passthrough', 'pca', 'pca_norm', 'tsne'], default='pca')\n",
    "u.n_words = u.create_int_slider(description='#words*', min=10, max=500, step=1, value=200)\n",
    "    \n",
    "w = interactive(display_correlation_network,\n",
    "                layout_algorithm=u.layout_algorithm,\n",
    "                threshold=u.threshold,\n",
    "                scale=u.scale,\n",
    "                metric=u.metric,\n",
    "                reducer=u.reducer,\n",
    "                n_words=u.n_words)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (u.text, ) +\n",
    "    (widgets.HBox((u.threshold,) + (u.reducer,) + (u.metric,)),) +\n",
    "    (widgets.HBox((u.n_words,) + (u.layout_algorithm,) + (u.scale,)),) +\n",
    "    (u.progress,) +\n",
    "    (w.children[-1],)))\n",
    "\n",
    "w.update()\n",
    "                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Topic Similarity using 2D T-SNE Dimensionality Reduction\n",
    "FIXME: var title = circle.data.words[index]; ska vara var title = circle.data.words[topic_id];???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "import types\n",
    "tr_data = types.SimpleNamespace(\n",
    "    X_n_space=None,\n",
    "    X_m_space=None,\n",
    "    n_words=None,\n",
    "    method=None,\n",
    "    corpus_documents=state.get_corpus_documents(),\n",
    "    topic_proportions=state.get_topic_proportions(),\n",
    "    tokens=state.get_topics_tokens_as_text(n_words=200)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot 2d utility function\n",
    "def plot_2d_vector_space(X_2_space, proportions=None, k = 250, m = 10,\n",
    "                         description=None, dom_id='id99', glyph_style=None, label_style=None):\n",
    "    global tr_data\n",
    "    xs, ys = zip(*X_2_space)\n",
    "    n_dim = len(xs)\n",
    "    item_ids = description.index if not description is None else range(0, n_dim)\n",
    "    source = ColumnDataSource(\n",
    "        dict(xs=list(xs),\n",
    "             ys=list(ys),\n",
    "             size=(k * proportions + m) if not proportions is None else [m] * n_dim,\n",
    "             text=description if not description is None else item_ids,\n",
    "             item_id=item_ids\n",
    "        )\n",
    "    )\n",
    "    p = figure(plot_width=800, plot_height=800, title='', tools=TOOLS)\n",
    "    \n",
    "    glyph_style = extend(dict(color='green', alpha=0.2, hover_color='red') , glyph_style or {})\n",
    "    cr = p.circle(x='xs', y='ys', size='size', source=source, **glyph_style)\n",
    "    \n",
    "    label_style = extend(dict(level='overlay', text_align='center', text_baseline='middle',\n",
    "                              text_font_size='8pt') , label_style or {})\n",
    "    labels = bm.LabelSet(x='xs', y='ys', text='item_id', source=source, **label_style)\n",
    "    \n",
    "    p.add_layout(labels)\n",
    "    \n",
    "    p.add_tools(bm.HoverTool(renderers=[cr], tooltips=None, callback=WidgetUtility.\\\n",
    "        glyph_hover_callback(source, 'item_id', text_ids=description.index, text=description, element_id=dom_id))\n",
    "    )\n",
    "    \n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea307d947104c38a441932d612ca565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='text99'/>\", placeholder=''), HBox(children=(IntSlider(value=200, continuous_update=False, description='#Words', max=500, min=10, step=10), IntSlider(value=30, continuous_update=False, description='Perplexity', min=1), IntProgress(value=0, max=5))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "def reduce_and_plot_vector_space(n_words, perplexity):\n",
    "    global state, u\n",
    "    method = 'tsne'\n",
    "    \n",
    "    u.progress.value = 1\n",
    "    \n",
    "    if tr_data.X_n_space is None or tr_data.n_words != n_words:\n",
    "        tr_data.X_n_space, _ = ModelUtility.compute_topic_terms_vector_space(state.get_lda(), n_words)\n",
    "        tr_data.X_m_space = None\n",
    "        \n",
    "    u.progress.value = 2\n",
    "    \n",
    "    if  tr_data.X_m_space is None or tr_data.method != method:\n",
    "        tr_data.X_m_space = VectorSpaceHelper.reduce_dimensions(\n",
    "            tr_data.X_n_space, method=method, n_components=2, perplexity=perplexity)\n",
    "        \n",
    "    tr_data.n_words = n_words\n",
    "    tr_data.method = method\n",
    "    \n",
    "    u.progress.value = 4\n",
    "    \n",
    "    p = plot_2d_vector_space(tr_data.X_m_space, proportions=tr_data.topic_proportions,\n",
    "        k=1000, m=10, description=tr_data.tokens, dom_id='text99')\n",
    "    u.progress.value = 5\n",
    "    show(p)\n",
    "    u.progress.value = 0\n",
    "    \n",
    "u = BaseWidgetUtility()\n",
    "u.n_words = u.create_int_slider(description='#Words', min=10, max=500, step=10, value=200)\n",
    "u.progress = u.create_int_progress_widget(min=0, max=5, step=1)\n",
    "u.perplexity = u.create_int_slider(description='Perplexity', min=1, max=100, step=1, value=30)\n",
    "u.text = u.create_text_widget(element_id='text99')\n",
    "\n",
    "w = interactive(reduce_and_plot_vector_space, n_words=u.n_words, perplexity=u.perplexity)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (u.text, ) +\n",
    "    (widgets.HBox((u.n_words,) + (u.perplexity,) + (u.progress, )),) + \n",
    "    (w.children[-1],)))\n",
    "\n",
    "w.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Document Similarity using LDA topic weights\n",
    "A similarity metric between documents is computed using a distance metric between the of document-topic vectors obtained from applying the trained LDA model. The vector space consists of n coordinates (i.e. 1036 segmented Daedalus articles) in m dimensions where m equals the number of topics. If all coordinates were to be used....  \n",
    "\n",
    "Problems:\n",
    "\n",
    "- It is desirable to exclude uninteresting topics from the computation and/or the plot. Documents with a close to even distriibution of topic weights are (clear?) candidates for exclusion.\n",
    "\n",
    "- Is there an established method of identifying the most (topically) interesting documents?\n",
    "- Use a goodness of fit to test against uniform discrete density distribution?\n",
    "  Wasserstein distance? Chi-square? KS-test\n",
    "\n",
    "#### First attempt using T-SNE\n",
    "\n",
    "- It is hard to ses clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/22433884/python-gensim-how-to-calculate-document-similarity-using-the-lda-model\n",
    "\n",
    "def compute_document_topic_vector_space(df):\n",
    "\n",
    "    #''' Filter out topics below given threshold '''\n",
    "    #df = df[df.weight][['document_id', 'topic_id', 'weight']]\n",
    "\n",
    "    ''' Create a dict (pair) for each topic-weight row '''\n",
    "    df['weight_dict'] = df.apply(lambda x: { int(x.topic_id): x.weight}, axis=1)\n",
    "\n",
    "    ''' Create a list of all dicts for each documents'''\n",
    "    df = df.groupby('document_id')['weight_dict'].apply(list)\n",
    "\n",
    "    ''' Merge the list of pair dicts into a single dict '''\n",
    "    df = df.apply(lambda L: { k: v for d in L for k, v in d.items() } )\n",
    "\n",
    "    ''' Fit the topic weighs into a sparse matrix (dimensions m_documents X n_topics)'''\n",
    "    v = DictVectorizer()\n",
    "    X_m_n_sparse = v.fit_transform(df)\n",
    "\n",
    "    return X_m_n_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2d262fcb164e99ae31b64e889ee89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='nx_id4'/>\", placeholder=''), HBox(children=(FloatSlider(value=0.01, continuous_update=False, description='Threshold', max=0.1, step=0.01), Dropdown(description='Reducer*', index=2, options=('pca', 'pca_norm', 'tsne'), value='tsne'), IntSlider(value=30, continuous_update=False, description='Perplexity', min=1), IntProgress(value=0, max=5))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# T-SNE 2D Visualization\n",
    "if 'ds_data' not in globals():\n",
    "    ds_data = types.SimpleNamespace(\n",
    "        X_m_n_sparse=None,\n",
    "        X_2_space=None,\n",
    "        threshold=None,\n",
    "        reducer=None,\n",
    "        perplexity=None,\n",
    "        G=None,\n",
    "        description=state.get_corpus_documents().rename(columns={'document': 'text'})['text']\n",
    "    )\n",
    "\n",
    "def plot_document_similarity_by_topics_tsne(threshold=0.001, reducer='tsne', perplexity=30):\n",
    "    global u, ds_data\n",
    "    \n",
    "    df = state.get_document_topic_weights()\n",
    "    \n",
    "    u.progress.value = 1\n",
    "    if ds_data.X_m_n_sparse is None:\n",
    "        ds_data.X_m_n_sparse = compute_document_topic_vector_space(df)\n",
    "        ds_data.threshold = threshold\n",
    "        ds_data.X_2_space = None\n",
    "    \n",
    "    u.progress.value = 2\n",
    "    if ds_data.X_2_space is None or ds_data.reducer != reducer  or ds_data.perplexity != perplexity or ds_data.threshold != threshold:\n",
    "        ds_data.X_2_space = VectorSpaceHelper.reduce_dimensions(\n",
    "            ds_data.X_m_n_sparse, method=reducer,\n",
    "            n_components=2, perplexity=perplexity)\n",
    "        ds_data.reduce = reducer\n",
    "        ds_data.perplexity = perplexity\n",
    "        \n",
    "    u.progress.value = 3\n",
    "\n",
    "    description = state.get_corpus_documents().rename(columns={'document': 'text'})['text']\n",
    "        \n",
    "    u.progress.value = 4\n",
    "    p = plot_2d_vector_space(ds_data.X_2_space, proportions=None,\n",
    "            k=1000, m=40, description=ds_data.description, dom_id='nx_id4', glyph_style=dict(alpha=0.05))\n",
    "    \n",
    "    u.progress.value = 5\n",
    "    show(p)\n",
    "    u.progress.value = 0\n",
    "\n",
    "u = BaseWidgetUtility()\n",
    "u.threshold = u.create_float_slider('Threshold', min=0.0, max=0.10, step=0.01, value=0.01)\n",
    "u.reducer = u.create_select_widget(label='Reducer*', values=['pca', 'pca_norm', 'tsne'], default='tsne')\n",
    "u.progress = u.create_int_progress_widget(min=0, max=5, step=1)\n",
    "u.perplexity = u.create_int_slider(description='Perplexity', min=1, max=100, step=1, value=30)\n",
    "u.text = u.create_text_widget(element_id='nx_id4')\n",
    "\n",
    "w = widgets.interactive(plot_document_similarity_by_topics_tsne,\n",
    "                threshold=u.threshold,\n",
    "                reducer=u.reducer,\n",
    "                perplexity=u.perplexity)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (u.text, ) +\n",
    "    (widgets.HBox((u.threshold,) + (u.reducer,) + (u.perplexity,) + (u.progress,)),) +\n",
    "    (w.children[-1],)))\n",
    "\n",
    "w.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_similarity_distribution():\n",
    "    df = state.get_document_topic_weights()\n",
    "    X_m_n_sparse = compute_document_topic_vector_space(df)\n",
    "    matrix = VectorSpaceHelper.compute_distance_matrix(X_m_n_sparse, metric='cosine')\n",
    "    x_dim, y_dim = matrix.shape\n",
    "    items = ((i, j, matrix[i,j]) for i, j in product(range(0,x_dim), range(0,y_dim)) if i < j)\n",
    "    ns, nm, ws = list(zip(*items))\n",
    "    df = pd.DataFrame(dict(n=ns,m=nm,w=ws))\n",
    "    df['similarity'] = (df.w*1000).astype('int')\n",
    "    p = df.groupby('similarity').size().iloc[0:970].plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### The same data  as a Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39da509af6274188a3282a9ba50fbf47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='nx_id_5'/>\", placeholder=''), HBox(children=(Dropdown(description='Reducer*', options=('none', 'pca', 'pca_norm', 'tsne'), value='none'), Dropdown(description='Metric*', index=3, options=('Correlation', 'Normalized Euclidean', 'Euclidean', 'Cosine', 'Squared Euclidean'), value='Cosine'))), HBox(children=(Dropdown(description='Layout', options=('Fruchterman-Reingold', 'Circular', 'Shell', 'Kamada-Kawai', 'Eigenvectors of Laplacian'), value='Fruchterman-Reingold'), IntSlider(value=100, continuous_update=False, description='Top', max=1000, min=100, step=100), IntProgress(value=0, max=6))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if True or 'cd99' not in globals():\n",
    "    cd99 = types.SimpleNamespace(\n",
    "        X_m_n_sparse=None,\n",
    "        top=None,\n",
    "        metric=None,\n",
    "        reducer=None,\n",
    "        document_topic_weights=state.get_document_topic_weights(),\n",
    "        corpus_documents=state.get_corpus_documents(),\n",
    "        topic_proportions=state.get_topic_proportions(),\n",
    "        G=None\n",
    "    )\n",
    "\n",
    "def plot_document_similarity_by_topics_network(\n",
    "    layout_algorithm, top, metric, reducer\n",
    "):\n",
    "    global u\n",
    "    scale = 1.0\n",
    "    threshold = 0.0\n",
    "    u.progress.value = 1\n",
    "    u.progress.description = 'Computing...'\n",
    "    df = cd99.document_topic_weights\n",
    "    \n",
    "    u.progress.value = 2\n",
    "    if cd99.X_m_n_sparse is None:\n",
    "        cd99.X_m_n_sparse = compute_document_topic_vector_space(df)\n",
    "        cd99.metric = None\n",
    "        u.progress.value = 3\n",
    "    metric = DISTANCE_METRICS[metric]\n",
    "    if cd99.metric != metric or cd99.top != top:\n",
    "        cd99.top = top\n",
    "        cd99.metric = metric\n",
    "        matrix = VectorSpaceHelper.compute_distance_matrix(cd99.X_m_n_sparse, metric=metric)\n",
    "        #edges = NetworkUtility.matrix_weight_iterator(matrix, threshold)\n",
    "        edges = NetworkUtility.df_stack_correlation_matrix(matrix, threshold=0.0, n_top=top)\n",
    "        u.progress.value = 4\n",
    "        G = nx.Graph()\n",
    "        G.add_weighted_edges_from(edges)\n",
    "        cd99.G = G\n",
    "        print(nx.info(cd99.G))\n",
    "\n",
    "    node_ids, degrees = list(zip(*list(cd99.G.degree(cd99.G.nodes()))))\n",
    "    node_proportions = pd.DataFrame(dict(node_id=node_ids, size=degrees)).set_index('node_id')\n",
    "    node_proportions['size'] *= 100\n",
    "    u.progress.value = 5\n",
    "    p = plot_correlation_network(\n",
    "        network=cd99.G,\n",
    "        layout_algorithm=layout_algorithm,\n",
    "        scale=scale,\n",
    "        threshold=0.0,\n",
    "        node_description=state.get_corpus_documents(),\n",
    "        node_proportions=node_proportions,\n",
    "        weight_scale=1.0,\n",
    "        normalize_weights=True\n",
    "    )\n",
    "    u.progress.description = ''\n",
    "    u.progress.value = 6\n",
    "    show(p)\n",
    "    u.progress.value = 0\n",
    "    \n",
    "u = BaseWidgetUtility()\n",
    "\n",
    "u.text = u.create_text_widget(element_id='nx_id_5')\n",
    "#u.scale = u.create_float_slider('Scale', min=0.0, max=1.0, step=0.1, value=1.0)\n",
    "u.reducer = u.create_select_widget(label='Reducer*', values=['none','pca','pca_norm','tsne'], default='none')\n",
    "u.progress = u.create_int_progress_widget(min=0, max=6, step=1, value=0)\n",
    "#u.threshold = u.create_float_slider('Threshold', min=0.01, max=1.0, step=0.01, value=0.1)\n",
    "u.top = u.create_int_slider('Top', min=100, max=1000, step=100, value=100)\n",
    "u.metric = u.create_select_widget(label='Metric*', values=list(DISTANCE_METRICS.keys()), default='Cosine')\n",
    "u.layout_algorithm = u.layout_algorithm_widget(list(layout_algorithms.keys()), default='Fruchterman-Reingold')\n",
    "\n",
    "w = widgets.interactive(plot_document_similarity_by_topics_network,\n",
    "                layout_algorithm=u.layout_algorithm,\n",
    "                #threshold=u.threshold,\n",
    "                top=u.top,\n",
    "                metric=u.metric,\n",
    "                reducer=u.reducer)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (u.text, ) +\n",
    "    #(u.threshold,) +\n",
    "    (widgets.HBox((u.reducer,) + (u.metric,)),) +\n",
    "    (widgets.HBox((u.layout_algorithm,) + (u.top,) + (u.progress,)),) +\n",
    "    (w.children[-1],)))\n",
    "\n",
    "w.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14a1c23152046ebbcafa0de27cdbb5b",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node_ids, degrees = list(zip(*list(cd99.G.degree(cd99.G.nodes()))))\n",
    "node_proportions = pd.DataFrame(dict(node_id=node_ids, size=degrees)).set_index('node_id')\n",
    "node_proportions['size'] *= 100\n",
    "node_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Clustering\n",
    "Compute topic clustering based on the distances between the T-SNE 2D coordinates. The SciPy linkage() takes an n x m matrice i.e. n points in m-dimensional vector space (can also take a 1D condensed distance matrix).\n",
    "\n",
    "1. The first plot takes the num_topics x 2 matrix that T-SNE produced as input\n",
    "2. The second example takes the \"raw\" vectorized num_topics x num_words matrix  as input i.e same input as to T-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Compute hierarchical/agglomerative clustering.\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html\n",
    "# https://stackoverflow.com/questions/11917779/how-to-plot-and-annotate-hierarchical-clustering-dendrograms-in-scipy-matplotlib\n",
    "\n",
    "if False:\n",
    "    C = linkage(X_reduced, method='single', metric='euclidean', optimal_ordering=False)\n",
    "else:\n",
    "    n_words = 50\n",
    "    X_n_space, _ = ModelUtility.compute_topic_terms_vector_space(current_lda, n_words)\n",
    "    C = linkage(X_n_space.toarray(), method='single', metric='euclidean', optimal_ordering=False)\n",
    "    \n",
    "plt.figure(figsize=(24,12))\n",
    "R = dendrogram(C, orientation='left')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame, display\n",
    "IFrame('./data/{}/pyldavis.html'.format(current_basename), width=900, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Compute and Plot Document Similarity using TF-IDF and T-SNE\n",
    "\n",
    "**FIXME** Fill in real TF-IDF values (from model) for tokens not in top-list (instead of zero)\n",
    "\n",
    "**FIXME** Simple (to simlple) document similarity metric, use text2vec instead!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim import corpora\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "class TfidfReducer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.corpus = corpora.MmCorpus(os.path.join(state.data_folder, state.basename, 'corpus.mm'))\n",
    "        self.dictionary = corpora.Dictionary.load(os.path.join(state.data_folder, state.basename, 'corpus.dict.gz'))\n",
    "        self.data_folder = data_folder\n",
    "        self.basename = basename\n",
    "        \n",
    "    def tfidf_vectors(self, tfidf, corpus, n_tokens):\n",
    "        for document in corpus:\n",
    "            yield tfidf[document][:n_tokens]\n",
    "\n",
    "    def tfidf_vectors_as_dicts(self, tfidf, corpus, n_tokens):\n",
    "        ''' Create a dict(token_1: weight, ..., token_n: weight } for each document '''\n",
    "        for tfidf_vector in self.tfidf_vectors(tfidf, corpus, n_tokens):\n",
    "            yield { x[0]: x[1] for x in tfidf_vector }\n",
    "        \n",
    "    def fit_transform(self, tfidf, corpus, n_tokens, perplexity=30):\n",
    "\n",
    "        ''' Align vectors... '''\n",
    "        v = DictVectorizer()\n",
    "        dict_vectors = self.tfidf_vectors_as_dicts(tfidf, corpus, n_tokens)\n",
    "        X = v.fit_transform(dict_vectors)\n",
    "        feature_names = v.get_feature_names()\n",
    "\n",
    "        print('Shape: ', X.shape)\n",
    "        reducer = TSNE(n_components=2, init='pca', random_state=2019, perplexity=perplexity)\n",
    "        X_reduced = reducer.fit_transform(X.toarray())\n",
    "\n",
    "        return X, feature_names, X_reduced\n",
    "\n",
    "class TfidfDocumentWidgets():\n",
    "    \n",
    "    def __init__(self, years):\n",
    "        self.text_id = 'document_text'\n",
    "        self.text = widgets.HTML(value=\"<span class='{}'/>\".format(self.text_id), placeholder='', description='')\n",
    "        self.perplexity = widgets.IntSlider(\n",
    "            min=1, max=200, step=1, value=30, description='Perplexity', continuous_update=False\n",
    "        )\n",
    "        self.word_count = widgets.IntSlider(\n",
    "            min=50, max=250, step=1, value=200, description='Word count', continuous_update=False\n",
    "        )\n",
    "        #self.dropdown = widgets.Dropdown(options=[], value='None', description='Dropdown', disabled=False)\n",
    "        self.year = widgets.Dropdown(\n",
    "            options=state.years, value=state.years[0], description='Year', disabled=False\n",
    "        )\n",
    "        \n",
    "    def setup_hover_callback_tool(self, cr):\n",
    "        code = \"\"\"\n",
    "        var indices = cb_data.index['1d'].indices;\n",
    "        if (indices.length > 0) {\n",
    "            var index = indices[0];\n",
    "            var topic_id = circle.data.topic_id[index];\n",
    "            var title = circle.data.words[index];\n",
    "            //var share = (100.0 * circle.data.topic_proportion[index]).toFixed(1).toString() + '%';\n",
    "            $('.\"\"\" + self.text_id + \"\"\"').html('DOC ' + topic_id.toString() + ': ' + title);\n",
    "        }\n",
    "        \"\"\"\n",
    "        callback = CustomJS(args={'document_glyph': cr.data_source}, code=code)\n",
    "        p.add_tools(HoverTool(tooltips=None, callback=callback, renderers=[cr]))\n",
    "        return HoverTool(tooltips=None, callback=callback, renderers=[cr])\n",
    "\n",
    "def plot_tf_idf_document_vector_space(X_reduced, document_index):\n",
    "    \n",
    "    xs, ys = zip(*X_reduced)\n",
    "    source = ColumnDataSource(\n",
    "        dict(xs=list(xs),\n",
    "             ys=list(ys),\n",
    "             #size=5,\n",
    "             #words=titles,\n",
    "             #topic_id=titles.index\n",
    "        )\n",
    "    )\n",
    "    p = figure(plot_width=800, plot_height=800, title='', tools=TOOLS)\n",
    "    cr = p.circle(x='xs', y='ys', size=5, source=source, alpha=0.2, hover_color='red')\n",
    "    show(p)\n",
    "    \n",
    "if 'corpus' is not in globals():\n",
    "    corpus = corpora.MmCorpus(os.path.join(state.data_folder, state.basename, 'corpus.mm'))\n",
    "    dictionary = corpora.Dictionary.load(os.path.join(state.data_folder, state.basename, 'corpus.dict.gz'))\n",
    "    id2document = ModelUtility.get_corpus_documents(data_folder, basename)\n",
    "    tfidf_corpus = TfidfCorpus(state.data_folder, state.basename, tfidf, corpus, n_tokens=200)\n",
    "    tfidf = TfidfModel(corpus)\n",
    "\n",
    "if 'X_reduced' is not in globals():\n",
    "    ''' This takes some time to compute...'''\n",
    "    document_tfidf_vectors = tfidf_vectors_as_dicts(tfidf, corpus)\n",
    "    X, feature_names, X_reduced = compute_document_pca(document_tfidf_vectors)\n",
    "    \n",
    "def display_tf_idf_document_vector_space(perplexity, word_count, year):\n",
    "    global X_reduced\n",
    "    plot_tf_idf_document_vector_space(X_reduced, perplexity)\n",
    "    \n",
    "u = TfidfDocumentWidgets(state.years)\n",
    "w = interactive(display_tf_idf_document_vector_space,\n",
    "                perplexity=u.perplexity, word_count=u.word_count, year=u.year)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (u.text,) + (widgets.HBox((u.year,) + (u.perplexity,) + (u.word_count,)),)\n",
    "    + (w.children[-1],)))\n",
    "        \n",
    "# w.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = state.get_document_topic_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document similarity using BOW document vectorization:\n",
    "https://de.dariah.eu/tatom/working_with_text.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goodness of Fit using **Kolmogorov-Smirnov** (alternatives are **chi square** and **maximum likelihood**) \n",
    "\n",
    "https://stats.stackexchange.com/questions/113464/understanding-scipy-kolmogorov-smirnov-test\n",
    "*\"For the KS test the p-value is itself distributed uniformly in [0,1] if the H0 is true (which it is if you test whether it your sample is from U(0,1)U(0,1) and the random number generation works okay). It therefore must \"vary wildly\" between 0 and 1, in fact its standard deviation is 1/121/12 which is roughly 0.3.\"*\n",
    "\n",
    "https://en.m.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test\n",
    "*\"The KolmogorovSmirnov statistic quantifies a distance between the empirical distribution function of the sample and the cumulative distribution function of the reference distribution, or between the empirical distribution functions of two samples. The null distribution of this statistic is calculated under the null hypothesis that the sample is drawn from the reference distribution (in the one-sample case) or that the samples are drawn from the same distribution (in the two-sample case). In each case, the distributions considered under the null hypothesis are continuous distributions but are otherwise unrestricted....The KolmogorovSmirnov test can be modified to serve as a goodness of fit test. \"* \n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html\n",
    "\n",
    "scipy.stats.wasserstein_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/113464/understanding-scipy-kolmogorov-smirnov-test\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "a = np.random.uniform(size=4999)\n",
    "\n",
    "print(scipy.stats.kstest(a, 'uniform'))\n",
    "\n",
    "rvs = df.loc[(df.document_id==0)]['weight']\n",
    "\n",
    "scipy.stats.kstest(rvs,'uniform')\n",
    "stats.kstest([1,2,3,4,5,6], 'uniform')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wasserstein_distance(a, [1.0 / len(a)] * len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = state.get_document_topic_weights()[['document_id', 'topic_id', 'weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bokeh.layouts import row\n",
    "category_size = 100\n",
    "\n",
    "topic_weights = state.get_document_topic_weights()[['document_id', 'topic_id', 'weight']]\n",
    "\n",
    "sd = topic_weights.weight.apply(lambda x: int(category_size * x))\n",
    "s_count = len(topic_weights)\n",
    "\n",
    "sd = sd[sd>0]\n",
    "v_count = len(sd)\n",
    "x_count = s_count - v_count\n",
    "d_count = len(topic_weights.document_id.unique())\n",
    "t_count = len(topic_weights.topic_id.unique())\n",
    "\n",
    "print('The data consists of {} documents, {} topics giving {} topic shares'.format(d_count, t_count, s_count))\n",
    "print('As much as {0:.2f}% of the documents topic shares are 0 ({1} out of {2})'.format(\n",
    "    100*x_count/s_count,x_count,s_count))\n",
    "print(\"The following graphs show the distribution of topic shares in absolute number and percentages\")\n",
    "\n",
    "ys = sd[sd>0].groupby(sd).size()\n",
    "xs = ys.index\n",
    "ysp = ys.apply(lambda x: x/v_count)\n",
    "\n",
    "p1 = figure(width=400, height=400, tools='',\n",
    "    x_axis_label='Number of topic shares',\n",
    "    y_axis_label='Percentage of all topics having that share')\n",
    "\n",
    "cd = p1.vbar(x=xs,width=1,top=ys,line_width=2)\n",
    "            \n",
    "p2 = figure(width=400, height=400, tools='',\n",
    "    x_axis_label='Topic''s share in document (percentage)',\n",
    "    y_axis_label='Percentage of all topics having that share')\n",
    "\n",
    "cd = p2.line(x=xs, y=ysp, line_width=2)\n",
    "show(row(p1,p2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.topic_token_weights\\\n",
    "    .drop('Unnamed: 0', axis=1)\\\n",
    "    .loc[lambda x: x.topic_id == 4]\\\n",
    "    .sort_values('weight',ascending=False)\\\n",
    "    .head(100)\n",
    "\n",
    "#.pipe(lambda x: x.topic_id == topic_id)\\\n",
    "#.sort_values('weight',ascending=False)[:max_n_words]\n",
    "#return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from bokeh.models import ColumnDataSource, CustomJS, Rect\n",
    "from bokeh.plotting import output_notebook, figure, show\n",
    "from bokeh.layouts import row\n",
    "\n",
    "output_notebook()\n",
    "N = 20\n",
    "img = np.empty((N,N), dtype=np.uint32)\n",
    "view = img.view(dtype=np.uint8).reshape((N, N, 4))\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        view[i, j, 0] = int(i/N*255)\n",
    "        view[i, j, 1] = 158\n",
    "        view[i, j, 2] = int(j/N*255)\n",
    "        view[i, j, 3] = 255\n",
    "        \n",
    "source = ColumnDataSource({'x':[], 'y':[], 'width':[], 'height':[]})\n",
    "\n",
    "def create_js_callback(axis, attribute):\n",
    "    return CustomJS(args=dict(source=source), code=\"\"\"\n",
    "        var data = source.data;\n",
    "        var start = cb_obj.start;\n",
    "        var end = cb_obj.end;\n",
    "        data['\"\"\" + axis + \"\"\"'] = [start + (end - start) / 2];\n",
    "        data['\"\"\" + attribute + \"\"\"'] = [end - start];\n",
    "        source.change.emit();\n",
    "    \"\"\")\n",
    "\n",
    "xrange_callback = create_js_callback('x', 'width')\n",
    "yrange_callback = create_js_callback('y', 'height')\n",
    "\n",
    "p1 = figure(title='Box Zoom Here', plot_width=400, plot_height=400,\n",
    "            x_range=(0,10), y_range=(0,10), tools ='box_zoom,wheel_zoom,pan,reset')\n",
    "p1.image_rgba(image=[img], x=[0], y=[0], dw=[10], dh=[10])\n",
    "p1.x_range.callback = xrange_callback\n",
    "p1.y_range.callback = yrange_callback\n",
    "\n",
    "p2 = figure(title='See Zoom Window Here', plot_width=400, plot_height=400, \n",
    "            x_range=(0,10), y_range=(0,10), tools=\"\")\n",
    "p2.image_rgba(image=[img], x=[0], y=[0], dw=[10], dh=[10])\n",
    "rect = Rect(x='x', y='y', width='width', height='height', fill_alpha=0, line_color='black')\n",
    "p2.add_glyph(source, rect)\n",
    "show(row(p1, p2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citing\n",
    "\n",
    "To cite NetworkX please use the following publication:\n",
    "\n",
    "*Aric A. Hagberg, Daniel A. Schult and Pieter J. Swart, Exploring network structure, dynamics, and function using NetworkX, in Proceedings of the 7th Python in Science Conference (SciPy2008), Gel Varoquaux, Travis Vaught, and Jarrod Millman (Eds), (Pasadena, CA USA), pp. 1115, Aug 2008*\n",
    "\n",
    "@inproceedings{rehurek_lrec,\n",
    "      title = {{Software Framework for Topic Modelling with Large Corpora}},\n",
    "      author = {Radim {\\v R}eh{\\r u}{\\v r}ek and Petr Sojka},\n",
    "      booktitle = {{Proceedings of the LREC 2010 Workshop on New\n",
    "           Challenges for NLP Frameworks}},\n",
    "      pages = {45--50},\n",
    "      year = 2010,\n",
    "      month = May,\n",
    "      day = 22,\n",
    "      publisher = {ELRA},\n",
    "      address = {Valletta, Malta},\n",
    "      note={\\url{http://is.muni.cz/publication/884893/en}},\n",
    "      language={English}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
