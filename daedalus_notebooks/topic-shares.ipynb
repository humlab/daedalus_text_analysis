{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize and Explore a LDA Topic Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run utility\n",
    "%run model-utility\n",
    "%run plot-utility\n",
    "%run widgets-utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* DONE    Fix bug in topic network\n",
    "* STARTED Add hover over selected glyphs that displats top topic terms\n",
    "* DONE    Add PCA/T-SNE 2D reduction topic \n",
    "* PENDING Topic clustering (dendrogram)?\n",
    "* PENDING Article similarity? (TF-IDF or document/topic PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Setup dependencies\n",
    "Import Python libraries and frameworks, and initialize the notebook.\n",
    "- bokeh\n",
    "- networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"e1f4b397-cac0-4269-9866-a3e0b51ef1c2\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"e1f4b397-cac0-4269-9866-a3e0b51ef1c2\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"e1f4b397-cac0-4269-9866-a3e0b51ef1c2\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'e1f4b397-cac0-4269-9866-a3e0b51ef1c2' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"e1f4b397-cac0-4269-9866-a3e0b51ef1c2\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"e1f4b397-cac0-4269-9866-a3e0b51ef1c2\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"e1f4b397-cac0-4269-9866-a3e0b51ef1c2\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'e1f4b397-cac0-4269-9866-a3e0b51ef1c2' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"e1f4b397-cac0-4269-9866-a3e0b51ef1c2\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load import_dependencies\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, IFrame\n",
    "import math\n",
    "from itertools import product\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%autosave 120\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file\n",
    "from bokeh.models.glyphs import VBar\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from bokeh.io import output_file, show, push_notebook\n",
    "from bokeh.models import BasicTicker, ColorBar, ColumnDataSource, LinearColorMapper, PrintfTickFormatter\n",
    "from bokeh.models import Circle, LabelSet, Label, Arrow, OpenHead, MultiLine, Whisker\n",
    "from bokeh.models import GraphRenderer, StaticLayoutProvider, LinearColorMapper, Plot, Range1d\n",
    "from bokeh.models import BoxSelectTool, TapTool, HoverTool, WheelZoomTool, BoxZoomTool, ResetTool, CustomJS\n",
    "from bokeh.models.graphs import from_networkx, NodesAndLinkedEdges, EdgesAndLinkedNodes\n",
    "from bokeh.core.properties import value, expr\n",
    "from bokeh.transform import transform, jitter\n",
    "import bokeh.palettes\n",
    "from bokeh.models.expressions import Stack\n",
    "from bokeh.layouts import column\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,previewsave\"\n",
    "AGGREGATES = { 'mean': np.mean, 'sum': np.sum, 'max': np.max, 'std': np.std }\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "data_folder = './data'\n",
    "current_basenames = ModelUtility.get_model_names(data_folder)\n",
    "current_basename = current_basenames[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Select a model\n",
    "Select one of the avaliable topic models stored in the ./data directory. New models are made avaliable by uploading them into seperate folders in ./data (for instance using Jupyter Lab). Note that the data must have been prepares with the **compute_lda_model.py** script, and all resulting files must be uploaded.\n",
    "Note that it can take some time (20-30 seconds) to load a model for the first due to large file sizes. Subsequent load is much faster since the system extracts data to CSV-files which gives faster loads.\n",
    "\n",
    "Note! Subsequent cells are NOT updated automatically when a new model is selected.\n",
    "Instead you must use the **play** button, or press **Shift-Enter** to execute the current cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f767d37a495415cb2acb08c597536e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(Dropdown(description='Topic model', layout=Layout(width='75%'), options=('topics_100_NN_PM__no_chunks_iterations_2000_lowercase_ldamodel', 'topics_50_NN_PM__no_chunks_iterations_2000_lowercase_ldamodel', 'topics_150_NN_PM__no_chunks_iterations_2000_lowercase_ldamodel', 'topics_150_NN_PM__no_chunks_iterations_2000_lowercase_ldamallet', 'topics_100_NN_PM__no_chunks_iterations_2000_lowercase_ldamallet', 'topics_50_NN_PM__no_chunks_iterations_2000_lowercase_ldamallet'), value='topics_100_NN_PM__no_chunks_iterations_2000_lowercase_ldamodel'), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Current model state\n",
    "class ModelState:\n",
    "    \n",
    "    def __init__(self, data_folder):\n",
    "        \n",
    "        self.data_folder = data_folder\n",
    "        self.basenames = ModelUtility.get_model_names(data_folder)\n",
    "        self.basename = self.basenames[0]\n",
    "        \n",
    "    def set_model(self, basename=None):\n",
    "\n",
    "        basename = basename or self.basename\n",
    "        \n",
    "        self.basename = basename\n",
    "      \n",
    "        self.document_topic_weights = ModelUtility.get_result_model_sheet(self.data_folder, basename, 'doc_topic_weights')\n",
    "        self.topic_token_weights = ModelUtility.get_result_model_sheet(self.data_folder, basename, 'topic_token_weights')\n",
    "        self.years = [None] + list(range(self.document_topic_weights.year.min(), self.document_topic_weights.year.max() + 1))\n",
    "        self.n_topics = self.document_topic_weights.topic_id.max() + 1\n",
    "        filename = os.path.join(self.data_folder, basename, 'gensim_model_{}.gensim.gz'.format(basename))\n",
    "        self._lda = None #LdaModel.load(filename)\n",
    "        self.top_tokens = None\n",
    "        self.corpus_documents = None\n",
    "        print(\"Current model: \" + self.basename.upper())\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_document_topic_weights(self, year=None, topic_id=None):\n",
    "        df = self.document_topic_weights\n",
    "        if year is None and topic_id is None:\n",
    "            return df\n",
    "        if topic_id is None:\n",
    "            return df[(df.year == year)]\n",
    "        if year is None:\n",
    "            return df[(df.topic_id == topic_id)]\n",
    "        return df[(df.year == year)&(df.topic_id == topic_id)]\n",
    "    \n",
    "    def get_unique_topic_ids(self):\n",
    "        return self.document_topic_weights['topic_id'].unique()\n",
    "    \n",
    "    def get_topic_weight_by_year_or_document(self, key='mean', year=None):\n",
    "        pivot_column = 'year' if year is None else 'document_id'    \n",
    "        df = self.get_document_topic_weights(year) \\\n",
    "            .groupby([pivot_column,'topic_id']) \\\n",
    "            .agg(AGGREGATES[key])[['weight']].reset_index()\n",
    "        return df, pivot_column\n",
    "\n",
    "    def get_lda(self):\n",
    "        if self._lda is None:\n",
    "            filename = 'gensim_model_{}.gensim.gz'.format(self.basename)\n",
    "            self._lda = LdaModel.load(os.path.join(self.data_folder, self.basename, filename))\n",
    "            print('LDA model loaded...')\n",
    "        return self._lda \n",
    "    \n",
    "    def get_topic_top_tokens(self, n_words=100, cache=True):\n",
    "        if cache and self.top_tokens is not None:\n",
    "            return self.top_tokens\n",
    "        top_tokens = ModelUtility.get_topic_titles(state.topic_token_weights, n_words=n_words)\n",
    "        if cache:\n",
    "            self.top_tokens = top_tokens\n",
    "        return top_tokens\n",
    "\n",
    "    def get_topic_year_aggregate_weights(self, fn, threshold):\n",
    "        df = self.document_topic_weights\n",
    "        #df = df[(df.weight>=threshold)]\n",
    "        df = df.groupby(['year', 'topic_id']).agg(fn)['weight'].reset_index()\n",
    "        df = df[(df.weight>=threshold)]\n",
    "        return df\n",
    "    \n",
    "    def get_topic_proportions(self):\n",
    "        corpus_documents = self.get_corpus_documents()\n",
    "        document_topic_weights = self.get_document_topic_weights()\n",
    "        topic_proportion = ModelUtility.compute_topic_proportions(document_topic_weights, corpus_documents)\n",
    "        return topic_proportion\n",
    "    \n",
    "    def get_corpus_documents(self):\n",
    "        if self.corpus_documents is None:\n",
    "            self.corpus_documents = ModelUtility.get_corpus_documents(self.data_folder, self.basename)\n",
    "        return self.corpus_documents\n",
    "\n",
    "state = ModelState(data_folder)\n",
    "\n",
    "wdg_basename = widgets.Dropdown(\n",
    "    options=state.basenames,\n",
    "    value=state.basename,\n",
    "    description='Topic model',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='75%')\n",
    ")\n",
    "wdg_model = interactive(state.set_model, basename=wdg_basename)\n",
    "#state = state.set_model();\n",
    "#clear_output()\n",
    "display(widgets.VBox((wdg_basename,) + (wdg_model.children[-1],)))\n",
    "wdg_model.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318d4ddd93b145d399bef7d65842d85c",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('precision', 10)\n",
    "#state.get_document_topic_weights(year=None, topic_id=0)\n",
    "state.document_topic_weights[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'År Maskin Polsunov Tid Belysning Del Stockholm Telegraf Ångmaskin Metall Vatten Tal Zander Arbete Gång Sågverk Persson Polsunovs Luft Museum Ljus Sida Bolag Försök Anläggning Vanadin Mineral Gustaf Början Rörelse Ritning Syra Delsbo Sverige Dag Vattenkraft Carl Ryssland Cylinder Scheele Glödlampa Ämne Danilevskij Hjälp Pulver Bild Plats Pud Krona Sten Ab Hälsingland Grund Sätt Modell Såg Historia Material Porfyrverket Foto Furusund Värme Slut Marma Kropp Maj Månad Krom Uppfinning Tungsten Eld Molybden Land Jord Station Industri Verk Järn Näs Ledning Form Område Sefström Mängd Drift Arkiv Kolv Volfram Broder April Pris Teknik Projekt Kraft Båglampa Tillverkning Verkstad Artikel Elektrifiering Bergman'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.get_topic_top_tokens(n_words=100, cache=True).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Topic Wordclouds\n",
    "**FIXME**: Wordcloud is not displayed when when cell is executed (known problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d69ffc26ede4535bc7231a7cecfc8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value='', placeholder=''), HBox(children=(Button(description='<<', style=ButtonStyle(button_color='lightgreen')), Button(description='>>', style=ButtonStyle(button_color='lightgreen')), IntSlider(value=0, continuous_update=False, description='Topic ID', max=99), IntSlider(value=50, continuous_update=False, description='Word count', max=500, min=1))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display LDA topic's token wordcloud\n",
    "\n",
    "opts = { 'max_font_size': 100, 'background_color': 'white', 'width': 800, 'height': 800 }\n",
    "\n",
    "z = TopicWidgets(state.n_topics, years=None, word_count=True)\n",
    "\n",
    "def display_wordcloud(topic_id=0, n_words=100):\n",
    "    global state\n",
    "    df_temp = state.topic_token_weights\n",
    "    tokens = state.get_topic_top_tokens(n_words=200, cache=True).iloc[topic_id]\n",
    "    z.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "    WordcloudUtility.plot_wordcloud(df_temp, 'token', 'weight', max_words=n_words, **opts)\n",
    "\n",
    "interactive_widget = interactive(display_wordcloud, topic_id=z.topic_id, n_words=z.word_count)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (z.text,) +\n",
    "    (widgets.HBox((z.prev_topic_id,) +(z.next_topic_id,) + (z.topic_id,) + (z.word_count,)),) +\n",
    "    (interactive_widget.children[-1],)))\n",
    "interactive_widget.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plot Topic's Weight Over Time\n",
    "Display a specific topics share over time as well as listing topic terms in descending order (based on yearly mean weight over all documents). The *whisker* displays max and mean topic weight for given year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ecd93ab38749418ae3775566f7198d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value='', placeholder=''), HBox(children=(Button(description='<<', style=ButtonStyle(button_color='lightgreen')), Button(description='>>', style=ButtonStyle(button_color='lightgreen')), IntSlider(value=0, continuous_update=False, description='Topic ID', max=99), Dropdown(description='Year', options=(None, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014), value=None), Dropdown(description='Aggregate', options=('mean', 'max', 'std'), value='mean'))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a topic in selected LDA topic model\n",
    "\n",
    "def plot_topic_over_time(df, pivot_column, value_column, topic_id=0, year=None, whisker=False):\n",
    "\n",
    "    source = ColumnDataSource(df)\n",
    "    p = figure(plot_width=900, plot_height=600, title='', tools=TOOLS, toolbar_location=\"right\")\n",
    "    p.xaxis[0].axis_label = pivot_column.title()\n",
    "    p.yaxis[0].axis_label = value_column.title() + ('weight' if value_column != 'weight' else '')\n",
    "    p.y_range.start = 0.0\n",
    "    p.y_range.end = 1.0\n",
    "\n",
    "    day_width = 60*60*24*1000\n",
    "    glyph = VBar(x=pivot_column, top=value_column, bottom=0, width=1, fill_color=\"#b3de69\")\n",
    "    p.add_glyph(source, glyph)\n",
    "    if whisker and year is None:\n",
    "        p.add_layout(\n",
    "            Whisker(source=source, base=pivot_column, upper=\"max\", lower=value_column)\n",
    "        )\n",
    "    if not year is None: print(df_temp[['index', 'document', 'topic_id', 'weight']])\n",
    "    return p\n",
    "\n",
    "def display_topic_over_time(topic_id, year, value_column):\n",
    "    global state\n",
    "\n",
    "    tokens = state.get_topic_top_tokens(n_words=200, cache=True).iloc[topic_id]\n",
    "    z.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "\n",
    "    pivot_column = 'year' if year is None else 'document_id'\n",
    "    value_column = value_column if year is None else 'weight'\n",
    "    \n",
    "    df = state.document_topic_weights[(state.document_topic_weights.topic_id==topic_id)]\n",
    "    \n",
    "    if year is None:\n",
    "        df = df.groupby([pivot_column, 'topic_id']).agg([np.mean, np.max, np.std])['weight'].reset_index()\n",
    "        df.columns = ['year', 'topic_id', 'mean', 'max', 'std']\n",
    "    else:\n",
    "        df = df[(df.year==year)]\n",
    "        \n",
    "    p = plot_topic_over_time(df, pivot_column, value_column, topic_id, year,  False)\n",
    "    show(p)\n",
    "    \n",
    "z = TopicWidgets(state.n_topics, state.years)\n",
    "z.aggregate = z.create_select_widget('Aggregate', ['mean', 'max', 'std'], default='mean')\n",
    "w = interactive(display_topic_over_time, topic_id=z.topic_id, year=z.year, value_column=z.aggregate)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (z.text,) + \n",
    "    (widgets.HBox((z.prev_topic_id,) + (z.next_topic_id,) + (z.topic_id,) + (z.year,) + (z.aggregate,)),) + \n",
    "    (w.children[-1],)))\n",
    "w.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step: Stacked Bar of Most Relevant Topics\n",
    "Display topic shares in descending order as a stacked bar chart. Order is based on selected aggregate function.\n",
    "FIXME: HTML span (class roger) must be unique!! (constructor argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad8f9b19e564c5abf26a57cfbc7ef6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='topic_share_plot'/>\", placeholder=''), HBox(children=(Dropdown(description='Aggregate', index=2, options=('sum', 'max', 'mean', 'std'), value='mean'), IntSlider(value=3, continuous_update=False, description='Topic count', max=99), Dropdown(description='Year', options=(None, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014), value=None))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot topic shares (year aggregate or per document for selected year)\n",
    "\n",
    "def prepare_stacked_topic_share_data(key, n_topics, year):\n",
    "    global state\n",
    "    pivot_column = 'year' if year is None else 'document_id'\n",
    "    \n",
    "    df_data = state.get_document_topic_weights(year)\n",
    "\n",
    "    df = ModelUtility.get_document_topic_weights_pivot(df_data, AGGREGATES[key], pivot_column)\n",
    "    df.set_index(pivot_column, inplace=True)\n",
    "    \n",
    "    n_topics = min(len(df.columns), n_topics)\n",
    "    topic_toplist = df[df.columns].sum().sort_values(axis=0, ascending=False)\n",
    "    df_top = df[topic_toplist[:n_topics].index].copy()\n",
    "\n",
    "    df = df_top.reset_index()\n",
    "    df.columns = [ str(x) for x in  df.columns ]\n",
    "    \n",
    "    return df, pivot_column, n_topics\n",
    "\n",
    "def generate_category_colors(n_items, palette=bokeh.palettes.Category20[20]):\n",
    "    ''' Repeat palette to get n_items colors '''\n",
    "    colors = (((n_items // len(palette)) + 1) * palette)[:n_items]\n",
    "    return colors\n",
    "\n",
    "def plot_stacked_bar_of_topic_over_time(df, pivot_column, key='mean', n_topics=3, year=None, n_words=100):\n",
    "    \n",
    "    categories = list(df.columns[1:])\n",
    "    colors = generate_category_colors(n_topics)\n",
    "    source = ColumnDataSource(df)\n",
    "    \n",
    "    p = figure(plot_width=900, plot_height=800, title=state.basename, tools=TOOLS, toolbar_location=\"right\")\n",
    "    \n",
    "    p.xaxis[0].axis_label = key.title() + ' weight'\n",
    "    p.yaxis[0].axis_label = pivot_column.title()\n",
    "    \n",
    "    #legend = [ value(x) for x in categories ]\n",
    "    #p.hbar_stack(categories, y=pivot_column, source=source, color=colors, height=0.5, legend=legend)\n",
    "        \n",
    "    bottoms, tops = [], []\n",
    "    for i, category in enumerate(categories):\n",
    "        tops = tops + [category]\n",
    "        cr = p.hbar(y=pivot_column,\n",
    "                    left=expr(Stack(fields=bottoms)),\n",
    "                    right=expr(Stack(fields=tops)),\n",
    "                    color=colors[i],\n",
    "                    height=0.5,\n",
    "                    source=source,\n",
    "                    legend='Topic ' + str(category))\n",
    "        topic_id = int(category)\n",
    "        tooltip = 'ID {}: {}'.format(topic_id, state.get_topic_top_tokens(n_words=200, cache=True).iloc[topic_id])\n",
    "        p.add_tools(HoverTool(tooltips=tooltip, renderers=[cr]))\n",
    "        bottoms = bottoms + [category]\n",
    "            \n",
    "    return p\n",
    "\n",
    "def display_stacked_bar_of_topic_over_time(key='mean', n_topics=3, year=None):\n",
    "    \n",
    "    global state\n",
    "    \n",
    "    ''' Prepare the plot data '''\n",
    "    \n",
    "    df, pivot_column, n_topics = prepare_stacked_topic_share_data(key, n_topics, year)\n",
    "    \n",
    "    #p1 = plot_stacked_bar_of_topic_over_time(df, pivot_column, key, n_topics, year, True)\n",
    "    p = plot_stacked_bar_of_topic_over_time(df, pivot_column, key, n_topics, year)\n",
    "    show(p)\n",
    "    \n",
    "z = TopTopicWidgets(state.n_topics, state.years, aggregates=list(AGGREGATES.keys()), text_id='topic_share_plot')\n",
    "w = interactive(display_stacked_bar_of_topic_over_time, n_topics=z.topics_count,  key=z.aggregate, year=z.year)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (z.text,) + \n",
    "    (widgets.HBox((z.aggregate,) + (z.topics_count,) + (z.year,)),) + \n",
    "    (w.children[-1],)))\n",
    "\n",
    "w.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Topic Weights\n",
    "List aggregated topic weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc238c2521024758b461395b9ea6302e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='text_id'/>\", placeholder=''), HBox(children=(Dropdown(description='Aggregate', index=2, options=('sum', 'max', 'mean', 'std'), value='mean'), Dropdown(description='Year', options=(None, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014), value=None))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Folded code\n",
    "import IPython.display # import display, HTML\n",
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "def plot_stacked_bar_of_topic_over_time(key='mean', year=None):\n",
    "    global state\n",
    "    pivot_column = 'year' if year is None else 'document_id'   \n",
    "    df_data = state.get_document_topic_weights(year)\n",
    "    df_temp = ModelUtility.get_document_topic_weights_pivot(df_data, AGGREGATES[key], pivot_column)\n",
    "    df_temp.set_index(pivot_column, inplace=True)\n",
    "    IPython.display.display(df_temp.head(5))\n",
    "    \n",
    "z = TopTopicWidgets(state.n_topics, state.years, aggregates=list(AGGREGATES.keys()))\n",
    "w = interactive(plot_stacked_bar_of_topic_over_time, key=z.aggregate, year=z.year)\n",
    "\n",
    "display(widgets.VBox((z.text,) +  (widgets.HBox((z.aggregate,) + (z.year,)),) +  (w.children[-1],)))\n",
    "w.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot (or heatmap) of topic shares per year or document\n",
    "Display topic shares as a scatter plot using gradient color for topic's weight.\n",
    "FIXME: Display only every 10th tick marker\n",
    "FIXME: Display words when hover is on y-axis instead (higlight entire row)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c78fdb76870404495b89e8d34d36b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Aggregate', index=2, options=('sum', 'max', 'mean', 'std'), value='mean'), Dropdown(description='Glyph', options=('Circle', 'Square'), value='Circle'), Dropdown(description='Year', options=(None, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014), value=None))), HTML(value=\"<span class='topic_relevance'/>\", placeholder=''), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_topic_relevance_by_year\n",
    "\n",
    "def setup_glyph_coloring(df):\n",
    "    max_weight = df.weight.max()\n",
    "    #colors = list(reversed(bokeh.palettes.Greens[9]))\n",
    "    colors = [\"#efefef\", \"#75968f\", \"#a5bab7\", \"#c9d9d3\", \"#e2e2e2\", \"#dfccce\", \"#ddb7b1\", \"#cc7878\",\n",
    "              \"#933b41\", \"#550b1d\"]\n",
    "    mapper = LinearColorMapper(palette=colors, low=df.weight.min(), high=max_weight)\n",
    "    color_transform = transform('weight', mapper)\n",
    "    color_bar = ColorBar(color_mapper=mapper, location=(0, 0),\n",
    "                         ticker=BasicTicker(desired_num_ticks=len(colors)),\n",
    "                         formatter=PrintfTickFormatter(format=\" %5.2f\"))\n",
    "    return color_transform, color_bar\n",
    "\n",
    "def plot_topic_relevance_by_year(df, xs, ys, glyph, titles, text_id):\n",
    "\n",
    "    ''' Setup axis categories '''\n",
    "    x_range = list(map(str, df[xs].unique()))\n",
    "    y_range = list(map(str, df[ys].unique()))\n",
    "    \n",
    "    ''' Setup coloring and color bar '''\n",
    "    color_transform, color_bar = setup_glyph_coloring(df)\n",
    "    \n",
    "    source = ColumnDataSource(df)\n",
    "\n",
    "    p = figure(title=\"Topic heatmap\", toolbar_location=None, tools=\"\", x_range=x_range,\n",
    "           y_range=y_range, x_axis_location=\"above\", plot_width=900, plot_height=900)\n",
    "\n",
    "    args = dict(x=xs, y=ys, source=source, alpha=1.0, hover_color='red')\n",
    "    \n",
    "    if glyph == 'Circle':\n",
    "        cr = p.circle(color=color_transform, **args)\n",
    "    else:\n",
    "        cr = p.rect(width=1, height=1, line_color=None, fill_color=color_transform, **args)\n",
    "\n",
    "    p.x_range.range_padding = 0\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"5pt\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    p.xaxis.major_label_orientation = 1.0\n",
    "    p.add_layout(color_bar, 'right')\n",
    "    \n",
    "    p.add_tools(HoverTool(tooltips=None, callback=WidgetUtility.glyph_hover_callback(\n",
    "        source, 'topic_id', titles.index, titles, text_id), renderers=[cr]))\n",
    "    \n",
    "    return p\n",
    "    \n",
    "def display_topic_relevance_by_year(key='mean', year=None, glyph='Circle'):\n",
    "    global state\n",
    "    titles = ModelUtility.get_topic_titles(state.topic_token_weights, n_words=100)\n",
    "    df, pivot_column = state.get_topic_weight_by_year_or_document(key=key, year=year)\n",
    "    df[pivot_column] = df[pivot_column].astype(str)\n",
    "    df['topic_id'] = df.topic_id.astype(str)\n",
    "    p = plot_topic_relevance_by_year(df, xs=pivot_column, ys='topic_id', glyph=glyph,\n",
    "                                     titles=titles, text_id='topic_relevance')\n",
    "    show(p)\n",
    "    \n",
    "u = TopTopicWidgets(0, state.years, aggregates=list(AGGREGATES.keys()), text_id='topic_relevance')\n",
    "u.glyph = widgets.Dropdown(options=['Circle', 'Square'], value='Circle', description='Glyph', disabled=False)\n",
    "\n",
    "w = interactive(display_topic_relevance_by_year, key=u.aggregate, year=u.year, glyph=u.glyph)\n",
    "\n",
    "display(widgets.VBox((widgets.HBox((u.aggregate,) + (u.glyph,) + (u.year,)),) + (u.text,) + (w.children[-1],)))\n",
    "        \n",
    "w.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Classes for Network Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# NetworkX\n",
    "%run widgets-utility\n",
    "import math\n",
    "import community # pip3 install python-louvain packages\n",
    "from networkx.algorithms import bipartite\n",
    "import networkx as nx\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "import inspect\n",
    "\n",
    "DISTANCE_METRICS = {\n",
    "    # 'Bray-Curtis': 'braycurtis',\n",
    "    # 'Canberra': 'canberra',\n",
    "    # 'Chebyshev': 'chebyshev',\n",
    "    # 'Manhattan': 'cityblock',\n",
    "    'Correlation': 'correlation',\n",
    "    'Cosine': 'cosine',\n",
    "    'Euclidean': 'euclidean',\n",
    "    # 'Mahalanobis': 'mahalanobis',\n",
    "    # 'Minkowski': 'minkowski',\n",
    "    'Normalized Euclidean': 'seuclidean',\n",
    "    'Squared Euclidean': 'sqeuclidean'\n",
    "}\n",
    "\n",
    "\n",
    "layout_algorithms = {\n",
    "    'Fruchterman-Reingold': lambda x,**args: nx.spring_layout(x,**args),\n",
    "    'Eigenvectors of Laplacian':  lambda x,**args: nx.spectral_layout(x,**args),\n",
    "    'Circular': lambda x,**args: nx.circular_layout(x,**args),\n",
    "    'Shell': lambda x,**args: nx.shell_layout(x,**args),\n",
    "    'Kamada-Kawai': lambda x,**args: nx.kamada_kawai_layout(x,**args)\n",
    "}\n",
    "\n",
    "class NetworkMetricHelper:\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_centrality(network):\n",
    "        centrality = nx.algorithms.centrality.betweenness_centrality(network)   \n",
    "        _, nodes_centrality = zip(*sorted(centrality.items()))\n",
    "        max_centrality = max(nodes_centrality)\n",
    "        centrality_vector = [7 + 10 * t / max_centrality for t in nodes_centrality]\n",
    "        return centrality_vector\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_partition(network):\n",
    "        partition = community.best_partition(network)\n",
    "        p_, nodes_community = zip(*sorted(partition.items()))\n",
    "        return nodes_community\n",
    "    \n",
    "    @staticmethod\n",
    "    def partition_colors(nodes_community, color_palette=None):\n",
    "        if color_palette is None:\n",
    "            color_palette = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00',\n",
    "                             '#ffff33','#a65628', '#b3cde3','#ccebc5','#decbe4','#fed9a6',\n",
    "                             '#ffffcc','#e5d8bd','#fddaec','#1b9e77','#d95f02','#7570b3','#e7298a',\n",
    "                             '#66a61e','#e6ab02','#a6761d','#666666']\n",
    "        community_colors = [ color_palette[x % len(color_palette)] for x in nodes_community ]\n",
    "        return community_colors\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_alpha_vector(value_vector):\n",
    "        max_value = max(value_vector)\n",
    "        alphas = list(map(lambda h: 0.1 + 0.6 * (h / max_value), value_vector))\n",
    "        return alphas\n",
    "    \n",
    "extend = lambda a,b: a.update(b) or a\n",
    "filter_kwargs = lambda f, args: { k:args[k] for k in args.keys() if k in inspect.getargspec(f).args }\n",
    "\n",
    "class VectorSpaceHelper:\n",
    "    \n",
    "    #@staticmethod\n",
    "    #def create_vector_space(lda, n_words = 50):\n",
    "    #    X_n_space, _ = ModelUtility.compute_topic_terms_vector_space(lda, n_words)\n",
    "    #    return X_n_space\n",
    "    \n",
    "    #@staticmethod\n",
    "    #def reduce_dimensionality(X_m_space, reducer, normalize=True):\n",
    "    #    if normalize is True:\n",
    "    #        reducer = make_pipeline(reducer, Normalizer(copy=False))\n",
    "    #    X_n_norm = reducer.fit(X_m_space.toarray()).transform(X_m_space.toarray())\n",
    "    #    return X_n_norm\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_pca(X_m_space, **kwargs):\n",
    "        kwargs = filter_kwargs(PCA, kwargs)\n",
    "        X_n_space = PCA(**kwargs).fit_transform(X_m_space.toarray())\n",
    "        return X_n_space\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_pca_norm(X_m_space, normalize=True, **kwargs):\n",
    "        kwargs = filter_kwargs(PCA, kwargs)\n",
    "        reducer = PCA(**kwargs)\n",
    "        if normalize is True:\n",
    "            reducer = make_pipeline(reducer, Normalizer(copy=False))\n",
    "        X_n_norm = reducer.fit_transform(X_m_space.toarray())\n",
    "        return X_n_norm\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_tsne_norm(X_m_space, **kwargs):\n",
    "        kwargs = filter_kwargs(TSNE, kwargs)\n",
    "        kwargs = extend(dict(n_components=20, init='pca', random_state=55887, perplexity=30), kwargs)\n",
    "        reducer = TSNE(**kwargs)\n",
    "        X_n_norm = reducer.fit_transform(X_m_space.toarray())\n",
    "        return X_n_norm\n",
    "    \n",
    "    @staticmethod\n",
    "    def reduce_dimensions(X_m_space, method=None, **kwargs):\n",
    "        reducer = None\n",
    "        if method not in [ 'passthrough', 'pca', 'pca_norm', 'tsne']:\n",
    "            raise Exception('Method unknown')\n",
    "        if method in [ 'pca', 'pca_norm']:\n",
    "            kwargs = filter_kwargs(PCA.__init__, kwargs)\n",
    "            reducer = PCA(**kwargs)\n",
    "            if method == 'pca_norm':\n",
    "                reducer = make_pipeline(reducer, Normalizer(copy=False))\n",
    "        if method == 'tsne':\n",
    "            kwargs = filter_kwargs(TSNE.__init__, kwargs)\n",
    "            reducer = TSNE(**kwargs)\n",
    "        X = X_m_space.toarray() if hasattr(X_m_space, 'toarray') else X_m_space\n",
    "        X_n_space = X_m_space if reducer is None else reducer.fit_transform(X)\n",
    "        return X_n_space\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_distance_matrix(X_n_space, metric='euclidean'):\n",
    "        # https://se.mathworks.com/help/stats/pdist.html\n",
    "        X = X_n_space.toarray() if hasattr(X_n_space, 'toarray') else X_n_space\n",
    "        distances = distance.pdist(X, metric=metric)\n",
    "        distance_matrix = distance.squareform(distances)\n",
    "        return distance_matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_clustering(correlation_matrix):\n",
    "        # Z = hierarchy.linkage(correlation_matrix, 'single')\n",
    "        clustering = hierarchy.linkage(correlation_matrix)\n",
    "        return clustering\n",
    "    \n",
    "class NetworkUtility:\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_edge_layout_data(network, layout):\n",
    "\n",
    "        data = [ (u, v, d['weight'], [layout[u][0], layout[v][0]], [layout[u][1], layout[v][1]])\n",
    "                    for u, v, d in network.edges(data=True) ]\n",
    "\n",
    "        return zip(*data)\n",
    "        \n",
    "    #FIXME Merge these two methods\n",
    "    @staticmethod\n",
    "    def get_edges_source(network, layout, scale=1.0, normalize=False):\n",
    "\n",
    "        _, _, weights, xs, ys = NetworkUtility.get_edge_layout_data(network, layout)\n",
    "        norm = max(weights) if normalize else 1.0\n",
    "        weights = [ scale * x / norm for x in  weights ]\n",
    "        lines_source = ColumnDataSource(dict(xs=xs, ys=ys, weights=weights))\n",
    "        return lines_source\n",
    "    \n",
    "   \n",
    "    @staticmethod\n",
    "    def get_node_subset_source(network, layout, node_list = None):\n",
    "\n",
    "        layout_items = layout.items() if node_list is None else [ x for x in layout.items() if x[0] in node_list ]\n",
    "\n",
    "        nodes, nodes_coordinates = zip(*sorted(layout_items))\n",
    "        xs, ys = list(zip(*nodes_coordinates))\n",
    "\n",
    "        nodes_source = ColumnDataSource(dict(x=xs, y=ys, name=nodes, node_id=nodes))\n",
    "        return nodes_source\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_nodes_data_source(network, layout):\n",
    "\n",
    "        nodes, nodes_coordinates = zip(*sorted([ x for x in layout.items() ])) # if x[0] in line_nodes]))\n",
    "        nodes_xs, nodes_ys = list(zip(*nodes_coordinates))\n",
    "        nodes_source = ColumnDataSource(dict(x=nodes_xs, y=nodes_ys, name=nodes, node_id=nodes))\n",
    "        return nodes_source\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_network(df, source_field='source', target_field='target', weight='weight'):\n",
    "\n",
    "        G = nx.Graph()\n",
    "        nodes = list(set(list(df[source_field].values) + list(df[target_field].values)))\n",
    "        edges = [ (x, y, { weight: z })\n",
    "                 for x, y, z in [ tuple(x) for x in df[[source_field, target_field, weight]].values]]\n",
    "        G.add_nodes_from(nodes)\n",
    "        G.add_edges_from(edges)\n",
    "        return G\n",
    "\n",
    "    @staticmethod\n",
    "    def create_bipartite_network(df, source_field='source', target_field='target', weight='weight'):\n",
    "\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(set(df[source_field].values), bipartite=0)\n",
    "        G.add_nodes_from(set(df[target_field].values), bipartite=1)\n",
    "        edges = list(zip(df[source_field].values,df[target_field].values,df[weight].apply(lambda x: dict(weight=x))))\n",
    "        G.add_edges_from(edges)\n",
    "        return G\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bipartite_node_set(network, bipartite=0):\n",
    "        nodes = set(n for n,d in network.nodes(data=True) if d['bipartite']==bipartite) \n",
    "        others = set(network) - nodes\n",
    "        return list(nodes), list(others)\n",
    "\n",
    "    @staticmethod\n",
    "    def layout_args(layout_algorithm, network, scale):\n",
    "        args = {}\n",
    "        if layout_algorithm == 'Shell':\n",
    "            year_nodes, topic_nodes = get_bipartite_node_set(network, bipartite=0)   \n",
    "            args = dict(nlist=[year_nodes, topic_nodes])\n",
    "\n",
    "        if layout_algorithm == 'Fruchterman-Reingold':\n",
    "            k = scale #/ math.sqrt(network.number_of_nodes())\n",
    "            args = dict(dim=2, k=k, iterations=20, weight='weight', scale=0.5)\n",
    "\n",
    "        if layout_algorithm == 'Kamada-Kawai':\n",
    "            args = dict(dim=2, weight='weight', scale=1.0)\n",
    "\n",
    "        return args    \n",
    "    \n",
    "    @staticmethod\n",
    "    def create_network_from_correlation_matrix(correlation_matrix, weight='weight'):\n",
    "\n",
    "        G = nx.Graph()\n",
    "        cm = correlation_matrix\n",
    "        x_dim, y_dim = cm.shape\n",
    "\n",
    "        ''' Assign multiplicative inverse weights since closer should have hihger weights '''\n",
    "        edges = [ (i, j, { weight: 1.0 / cm[i,j]}) for i, j in product(range(0,x_dim), range(0,y_dim)) if i < j ]\n",
    "\n",
    "        G.add_nodes_from(range(0, max(x_dim,y_dim)))\n",
    "        G.add_edges_from(edges)\n",
    "\n",
    "        return G\n",
    "\n",
    "    #     #pos = nx.graphviz_layout(G, prog=\"twopi\") # twopi, neato, circo\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Year to Topic Network Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d1696d000f40be909aad591d34cc55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='nx_id1'/>\", placeholder=''), HBox(children=(Dropdown(description='Layout', index=2, options=('Shell', 'Eigenvectors of Laplacian', 'Fruchterman-Reingold', 'Kamada-Kawai', 'Circular'), value='Fruchterman-Reingold'), Dropdown(description='Aggregate', index=2, options=('sum', 'max', 'mean', 'std'), value='mean'))), HBox(children=(FloatSlider(value=0.0, continuous_update=False, description='Threshold', max=1.0, step=0.01), FloatSlider(value=0.1, continuous_update=False, description='Scale', max=1.0, step=0.01))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize year-to-topic correlations by means of topic-document-weight dimensional reduction\n",
    "#setup_glyph_id_text_hover_callback(topic_nodes_source, ids=titles.index, text=titles, element_id='nx_id1')\n",
    "     \n",
    "def plot_topic_year_network(network, layout, scale=1.0, titles=None):\n",
    "\n",
    "    year_nodes, topic_nodes = NetworkUtility.get_bipartite_node_set(network, bipartite=0)  \n",
    "    \n",
    "    year_source = NetworkUtility.get_node_subset_source(network, layout, year_nodes)\n",
    "    topic_source = NetworkUtility.get_node_subset_source(network, layout, topic_nodes)\n",
    "    lines_source = NetworkUtility.get_edges_source(network, layout, scale=6.0, normalize=False)\n",
    "    \n",
    "    edges_alphas = NetworkMetricHelper.compute_alpha_vector(lines_source.data['weights'])\n",
    "    \n",
    "    lines_source.add(edges_alphas, 'alphas')\n",
    "    \n",
    "    p = figure(plot_width=900, plot_height=900, x_axis_type=None, y_axis_type=None, tools=TOOLS)\n",
    "    \n",
    "    r_lines = p.multi_line('xs', 'ys', line_width='weights', alpha='alphas', color='black', source=lines_source)\n",
    "    r_years = p.circle('x', 'y', size=40, source=year_source, color='olive', level='overlay', line_width=1, alpha=0.90)\n",
    "    r_topics = p.circle('x', 'y', size=25, source=topic_source, color='skyblue', level='overlay', alpha=0.90)\n",
    "    \n",
    "    p.add_tools(HoverTool(renderers=[r_topics], tooltips=None, callback=WidgetUtility.\\\n",
    "        glyph_hover_callback(topic_source, 'node_id', text_ids=titles.index, text=titles, element_id='nx_id1'))\n",
    "    )\n",
    "\n",
    "    text_opts = dict(x='x', y='y', text='name', level='overlay', text_align='center', text_baseline='middle',\n",
    "                      x_offset=0, y_offset=0, text_font='Arial', text_font_size='8pt')\n",
    "    \n",
    "    p.add_layout(LabelSet(source=year_source, text_color='black', **text_opts))\n",
    "    p.add_layout(LabelSet(source=topic_source,  text_color='black', **text_opts))\n",
    "    \n",
    "    #selected_circle = Circle(fill_alpha=1, fill_color=\"olive\", line_color=None)\n",
    "    #nonselected_circle = Circle(fill_alpha=0.2, fill_color=\"blue\", line_color=\"firebrick\")\n",
    "    #r_topics.selection_glyph = selected_circle\n",
    "    #r_topics.nonselection_glyph = nonselected_circle\n",
    "    \n",
    "    return p\n",
    "    \n",
    "def display_topic_year_network(layout_algorithm, aggregate='mean', threshold=0.10, scale=1.0):\n",
    "    global state\n",
    "                                       \n",
    "    titles = state.get_topic_top_tokens()\n",
    "    df = state.get_topic_year_aggregate_weights(AGGREGATES[aggregate], threshold)\n",
    "    \n",
    "    #print(df_temp)\n",
    "    #return\n",
    "    \n",
    "    network = NetworkUtility.create_bipartite_network(df, 'year', 'topic_id')\n",
    "\n",
    "    args = NetworkUtility.layout_args(layout_algorithm, network, scale)\n",
    "    layout = (layout_algorithms[layout_algorithm])(network, **args)\n",
    "        \n",
    "    p = plot_topic_year_network(network, layout, scale=scale, titles=titles)\n",
    "    \n",
    "    show(p)\n",
    "\n",
    "u = TopTopicWidgets(text_id='nx_id1', aggregates=list(AGGREGATES.keys()), layout_algorithms=list(layout_algorithms.keys()))\n",
    "u.scale = u.create_float_slider('Scale', min=0.0, max=1.0, step=0.01, value=0.1)\n",
    "u.threshold = u.create_float_slider('Threshold', min=0.0, max=1.0, step=0.01, value=0.0)\n",
    "w = interactive(display_topic_year_network, layout_algorithm=u.layout_algorithm, aggregate=u.aggregate, threshold=u.threshold, scale=u.scale)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (u.text, ) +\n",
    "    (widgets.HBox((u.layout_algorithm, ) + (u.aggregate,)),) +\n",
    "    (widgets.HBox((u.threshold,) + (u.scale,)),) +\n",
    "    (w.children[-1],)))\n",
    "\n",
    "w.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Similarity Network\n",
    "This plot displays topic similarity based on euclidean distances between topic word vectors. Please note that the computations can take some time to exceute, especially for larger LDA models.\n",
    "\n",
    "1. Compute a multi dimensional topic vector space based on the top n words for each topic. Since the subset of words differs, and their positions differs between topics they need to be aligned in common space so that 1) each vector has the same dimension (i.e. number of unique top n tokens over all topics) and 2) each token has the same position within that space. (using sklearn DictVectorizer). The vector space will have as many dimensions as the number of unique top n words over all topics.\n",
    "2. Reduce the topic vector space into a 2D space (using sklearn PCA)\n",
    "3. Normalize the 2D space (sklearn Normalizer)\n",
    "\n",
    "TODO: DONE Use cosine similarity as alternativ to spatial distance\n",
    "TODO: Alternative to use 1) DONE topic-term vector space 2) DONE PCA nD 3) T-SNE\n",
    "TODO: Save network to file (either via pandas or networkx)\n",
    "TODO: Should partition/community be computed before or after network is filtered?\n",
    "\n",
    "Note: Steps 1 to 3 above (the most time consuming) are executed whenever an option marked with an asterix is changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Cached data\n",
    "import types\n",
    "nx_data = types.SimpleNamespace(\n",
    "    network=None,\n",
    "    X_n_space=None,\n",
    "    X_pca_norm=None,\n",
    "    X_tsne_norm=None,\n",
    "    distance_matrix=None,\n",
    "    metric=None,\n",
    "    reducer=None,\n",
    "    topic_proportions=None,\n",
    "    n_words = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc7f44d6f3a4cd4a1cbb4e54ee7c767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='nx_id3'/>\", placeholder=''), HBox(children=(FloatSlider(value=0.1, continuous_update=False, description='Threshold', max=1.0, step=0.01), Dropdown(description='Reducer*', index=1, options=('passthrough', 'pca', 'pca_norm', 'tsne'), value='pca'), Dropdown(description='Metric*', index=2, options=('Squared Euclidean', 'Normalized Euclidean', 'Cosine', 'Euclidean', 'Correlation'), value='Cosine'))), HBox(children=(IntSlider(value=200, continuous_update=False, description='#words*', max=500, min=10), Dropdown(description='Layout', index=2, options=('Shell', 'Eigenvectors of Laplacian', 'Fruchterman-Reingold', 'Kamada-Kawai', 'Circular'), value='Fruchterman-Reingold'), FloatSlider(value=0.1, continuous_update=False, description='Scale', max=1.0, step=0.01))), IntProgress(value=0, max=10), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization\n",
    "def plot_clustering_dendogram(clustering):\n",
    "    plt.figure(figsize=(16,6))\n",
    "    # https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n",
    "    R = dendrogram(clustering)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_correlation_network(\n",
    "    network,\n",
    "    layout_algorithm=None,\n",
    "    scale=1.0,\n",
    "    threshold=0.0,\n",
    "    node_description=None,\n",
    "    node_proportions=None\n",
    "):\n",
    "    \n",
    "    max_weight = max(nx.get_edge_attributes(network, 'weight').values())\n",
    "    filter_edges = [(u, v) for u, v, d in network.edges(data=True) if d['weight'] >= (threshold * max_weight)]\n",
    "    sub_network = network.edge_subgraph(filter_edges)\n",
    "    \n",
    "    args = NetworkUtility.layout_args(layout_algorithm, sub_network, scale)\n",
    "    layout = (layout_algorithms[layout_algorithm])(sub_network, **args)\n",
    "\n",
    "    lines_source = NetworkUtility.get_edges_source(sub_network, layout, scale=5.0, normalize=True)\n",
    "    nodes_source = NetworkUtility.create_nodes_data_source(sub_network, layout)\n",
    "\n",
    "    nodes_community = NetworkMetricHelper.compute_partition(sub_network)\n",
    "    community_colors = NetworkMetricHelper.partition_colors(nodes_community, bokeh.palettes.Category20[20])\n",
    "    nodes_weight = 2000 * node_proportions.iloc[list(sub_network.nodes)]\n",
    "    \n",
    "    nodes_source.add(nodes_community, 'community')\n",
    "    nodes_source.add(community_colors, 'community_color')\n",
    "    nodes_source.add(nodes_weight, 'size')\n",
    "       \n",
    "    p = figure(plot_width=900, plot_height=900, x_axis_type=None, y_axis_type=None) #, tools=tools)\n",
    "    \n",
    "    r_lines = p.multi_line('xs', 'ys', line_width='weights', color='black', source=lines_source)\n",
    "    r_nodes = p.circle('x', 'y', size='size', source=nodes_source, color='green', level='overlay', alpha=1.0)\n",
    "    \n",
    "    p.add_tools(HoverTool(renderers=[r_nodes], tooltips=None, callback=WidgetUtility.\\\n",
    "        glyph_hover_callback(nodes_source, 'node_id', text_ids=node_description.index, text=node_description, element_id='nx_id3'))\n",
    "    )\n",
    "    \n",
    "    text_opts = dict(x='x', y='y', text='name', level='overlay', text_align='center', text_baseline='middle',\n",
    "                      x_offset=0, y_offset=0,text_font='Arial')\n",
    "\n",
    "    r_nodes.glyph.fill_color = 'community_color'\n",
    "\n",
    "    p.add_layout(LabelSet(source=nodes_source, text_color='black', **text_opts))\n",
    "    \n",
    "    return p\n",
    "\n",
    "def display_correlation_network(\n",
    "    layout_algorithm, threshold=0.10, scale=1.0, metric='Euclidean', reducer='tsne', n_words=200):\n",
    "    global state, data, u\n",
    "\n",
    "    u.progress.value = 1\n",
    "    metric = DISTANCE_METRICS[metric]\n",
    "    n_components = 3 if reducer == 'tsne' else 20\n",
    "    perplexity=30\n",
    "    \n",
    "    node_description = state.get_topic_top_tokens()\n",
    "    node_proportions = state.get_topic_proportions()\n",
    "    #print(df_temp)\n",
    "    #return\n",
    "    u.progress.value = 2\n",
    "    if nx_data.network is None or nx_data.metric != metric or nx_data.reducer != reducer or nx_data.n_words != n_words:\n",
    "        nx_data.n_words = n_words\n",
    "        nx_data.metric, nx_data.reducer = metric, reducer\n",
    "        nx_data.pca_norm = None\n",
    "        nx_data.X_n_space, _ = ModelUtility.compute_topic_terms_vector_space(state.get_lda(), n_words=n_words)\n",
    "        u.progress.value = 3\n",
    "        nx_data.X_m_space = VectorSpaceHelper.\\\n",
    "                reduce_dimensions(nx_data.X_n_space, method=reducer, n_components=n_components, perplexity=perplexity)\n",
    "            \n",
    "        u.progress.value = 5\n",
    "        nx_data.distance_matrix = VectorSpaceHelper.compute_distance_matrix(nx_data.X_m_space, metric=metric)\n",
    "        u.progress.value = 7\n",
    "        nx_data.network = NetworkUtility.create_network_from_correlation_matrix(nx_data.distance_matrix)\n",
    "\n",
    "    u.progress.value = 8\n",
    "    p = plot_correlation_network(network=nx_data.network,\n",
    "                             layout_algorithm=layout_algorithm,\n",
    "                             scale=scale, threshold=threshold,\n",
    "                             node_description=node_description,\n",
    "                             node_proportions=node_proportions)\n",
    "    \n",
    "    u.progress.value = 10\n",
    "    show(p)\n",
    "    u.progress.value = 0\n",
    "    \n",
    "u = TopTopicWidgets(text_id='nx_id3', layout_algorithms=list(layout_algorithms.keys()))\n",
    "\n",
    "u.scale = u.create_float_slider('Scale', min=0.0, max=1.0, step=0.01, value=0.1)\n",
    "u.progress = u.create_int_progress_widget(min=0, max=10, step=2, value=0)\n",
    "u.threshold = u.create_float_slider('Threshold', min=0.0, max=1.0, step=0.01, value=0.10)\n",
    "u.metric = u.create_select_widget(label='Metric*', values=list(DISTANCE_METRICS.keys()), default='Cosine')\n",
    "u.reducer = u.create_select_widget(label='Reducer*', values=['passthrough', 'pca', 'pca_norm', 'tsne'], default='pca')\n",
    "u.n_words = u.create_int_slider(description='#words*', min=10, max=500, step=1, value=200)\n",
    "    \n",
    "w = interactive(display_correlation_network,\n",
    "                layout_algorithm=u.layout_algorithm,\n",
    "                threshold=u.threshold,\n",
    "                scale=u.scale,\n",
    "                metric=u.metric,\n",
    "                reducer=u.reducer,\n",
    "                n_words=u.n_words)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (u.text, ) +\n",
    "    (widgets.HBox((u.threshold,) + (u.reducer,) + (u.metric,)),) +\n",
    "    (widgets.HBox((u.n_words,) + (u.layout_algorithm,) + (u.scale,)),) +\n",
    "    (u.progress,) +\n",
    "    (w.children[-1],)))\n",
    "\n",
    "w.update()\n",
    "                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Topic Similarity using 2D T-SNE Dimensionality Reduction\n",
    "FIXME: var title = circle.data.words[index]; ska vara var title = circle.data.words[topic_id];???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "tr_data = types.SimpleNamespace(\n",
    "    X_n_space=None,\n",
    "    X_m_space=None,\n",
    "    n_words=None,\n",
    "    method=None,\n",
    "    corpus_documents=state.get_corpus_documents(),\n",
    "    topic_proportions=state.get_topic_proportions(),\n",
    "    tokens=state.get_topic_top_tokens(n_words=200)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot 2d utility function\n",
    "def plot_2d_vector_space(X_2_space, proportions=None, k = 250, m = 10,\n",
    "                         description=None, dom_id='id99', glyph_style=None, label_style=None):\n",
    "    global tr_data\n",
    "    xs, ys = zip(*X_2_space)\n",
    "    n_dim = len(xs)\n",
    "    item_ids = description.index if not description is None else range(0, n_dim)\n",
    "    source = ColumnDataSource(\n",
    "        dict(xs=list(xs),\n",
    "             ys=list(ys),\n",
    "             size=(k * proportions + m) if not proportions is None else [m] * n_dim,\n",
    "             text=description if not description is None else item_ids,\n",
    "             item_id=item_ids\n",
    "        )\n",
    "    )\n",
    "    p = figure(plot_width=800, plot_height=800, title='', tools=TOOLS)\n",
    "    \n",
    "    glyph_style = extend(dict(color='green', alpha=0.2, hover_color='red') , glyph_style or {})\n",
    "    cr = p.circle(x='xs', y='ys', size='size', source=source, **glyph_style)\n",
    "    \n",
    "    label_style = extend(dict(level='overlay', text_align='center', text_baseline='middle',\n",
    "                              text_font_size='8pt') , label_style or {})\n",
    "    labels = LabelSet(x='xs', y='ys', text='item_id', source=source, **label_style)\n",
    "    \n",
    "    p.add_layout(labels)\n",
    "    \n",
    "    p.add_tools(HoverTool(renderers=[cr], tooltips=None, callback=WidgetUtility.\\\n",
    "        glyph_hover_callback(source, 'item_id', text_ids=description.index, text=description, element_id=dom_id))\n",
    "    )\n",
    "    \n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9d553aa3db440894a0a5b8945cbd3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=\"<span class='text99'/>\", placeholder=''), HBox(children=(IntSlider(value=200, continuous_update=False, description='#Words', max=500, min=10, step=10), IntSlider(value=30, continuous_update=False, description='Perplexity', min=1), IntProgress(value=0, max=5))), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def reduce_and_plot_vector_space(n_words, perplexity):\n",
    "    global state, u\n",
    "    method = 'tsne'\n",
    "    \n",
    "    u.progress.value = 1\n",
    "    \n",
    "    if tr_data.X_n_space is None or tr_data.n_words != n_words:\n",
    "        tr_data.X_n_space, _ = ModelUtility.compute_topic_terms_vector_space(state.get_lda(), n_words)\n",
    "        tr_data.X_m_space = None\n",
    "        \n",
    "    u.progress.value = 2\n",
    "    \n",
    "    if  tr_data.X_m_space is None or tr_data.method != method:\n",
    "        tr_data.X_m_space = VectorSpaceHelper.reduce_dimensions(\n",
    "            tr_data.X_n_space, method=method, n_components=2, perplexity=perplexity)\n",
    "        \n",
    "    tr_data.n_words = n_words\n",
    "    tr_data.method = method\n",
    "    \n",
    "    u.progress.value = 4\n",
    "    \n",
    "    p = plot_2d_vector_space(tr_data.X_m_space, proportions=tr_data.topic_proportions,\n",
    "                                    k=1000, m=10, description=tr_data.tokens, dom_id='text99')\n",
    "    u.progress.value = 5\n",
    "    show(p)\n",
    "    u.progress.value = 0\n",
    "    \n",
    "u = BaseWidgetUtility()\n",
    "u.n_words = u.create_int_slider(description='#Words', min=10, max=500, step=10, value=200)\n",
    "u.progress = u.create_int_progress_widget(min=0, max=5, step=1)\n",
    "u.perplexity = u.create_int_slider(description='Perplexity', min=1, max=100, step=1, value=30)\n",
    "u.text = u.create_text_widget(element_id='text99')\n",
    "\n",
    "w = interactive(reduce_and_plot_vector_space, n_words=u.n_words, perplexity=u.perplexity)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (u.text, ) +\n",
    "    (widgets.HBox((u.n_words,) + (u.perplexity,) + (u.progress, )),) + \n",
    "    (w.children[-1],)))\n",
    "\n",
    "w.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Document Similarity using LDA topic weights\n",
    "A similarity metric between documents is computed using a distance metric between the of document-topic vectors obtained from applying the trained LDA model. The vector space consists of n coordinates (i.e. 1036 segmented Daedalus articles) in m dimensions where m equals the number of topics. If all coordinates were to be used....  \n",
    "\n",
    "Problems:\n",
    "\n",
    "- It is desirable to exclude topically uninteresting topics from the computation and/or the plot. Documents with a close to even distriibution of topic weights are (clear?) candidates for exclusion.\n",
    "\n",
    "- Is there an established method of identifying the most (topically) interesting documents?\n",
    "- Use a goodness of fit to test against uniform discrete density distribution?\n",
    "  Wasserstein distance? Chi-square? KS-test\n",
    "\n",
    "#### First attempt using T-SNE\n",
    "\n",
    "- It is hard to ses clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/22433884/python-gensim-how-to-calculate-document-similarity-using-the-lda-model\n",
    "\n",
    "def compute_document_topic_vector_space(df, threshold):\n",
    "\n",
    "    ''' Get all document topic weights (a total of n_documents X n_topics values)'''\n",
    "    df = state.get_document_topic_weights()\n",
    "\n",
    "    ''' Filter out topics below given threshold '''\n",
    "    df = df[df.weight > threshold][['document_id', 'topic_id', 'weight']]\n",
    "\n",
    "    ''' Create a dict (pair) for each topic-weight row '''\n",
    "    df['weight_dict'] = df.apply(lambda x: { int(x.topic_id): x.weight}, axis=1)\n",
    "\n",
    "    ''' Create a list of all dicts for each documents'''\n",
    "    df = df.groupby('document_id')['weight_dict'].apply(list)\n",
    "\n",
    "    ''' Merge the list of pair dicts into a single dict '''\n",
    "    df = df.apply(lambda L: { k: v for d in L for k, v in d.items() } )\n",
    "\n",
    "    ''' Fit the topic weighs into a sparse matrix (dimensions m_documents X n_topics)'''\n",
    "    v = DictVectorizer()\n",
    "    X_m_n_sparse = v.fit_transform(df)\n",
    "\n",
    "    return X_m_n_sparse\n",
    "\n",
    "def plot_document_similarity_by_topics_tsne(threshold=0.001, reducer='tsne', perplexity=30):\n",
    "    global u\n",
    "    \n",
    "    df = state.get_document_topic_weights()\n",
    "    \n",
    "    u.progress.value = 1\n",
    "    X_m_n_sparse = compute_document_topic_vector_space(df, threshold)\n",
    "    \n",
    "    u.progress.value = 2\n",
    "    X_2_space = VectorSpaceHelper.reduce_dimensions(X_m_n_sparse, method=reducer, n_components=2, perplexity=perplexity)\n",
    "\n",
    "    u.progress.value = 3\n",
    "    document_proportions = None\n",
    "    description = state.get_corpus_documents()\\\n",
    "        .copy().rename(columns={'document_id': 'item_id', 'text': 'document_name'})\n",
    "        \n",
    "    u.progress.value = 4\n",
    "    p = plot_2d_vector_space(X_2_space, proportions=document_proportions,\n",
    "                        k=1000, m=40, description=description, dom_id='nx_id4', glyph_style=dict(alpha=0.05))\n",
    "    \n",
    "    u.progress.value = 5\n",
    "    show(p)\n",
    "    u.progress.value = 0\n",
    "\n",
    "u = BaseWidgetUtility()\n",
    "u.threshold = u.create_float_slider('Threshold', min=0.0, max=0.10, step=0.01, value=0.01)\n",
    "u.reducer = u.create_select_widget(label='Reducer*', values=['pca', 'pca_norm', 'tsne'], default='tsne')\n",
    "u.progress = u.create_int_progress_widget(min=0, max=5, step=1)\n",
    "u.perplexity = u.create_int_slider(description='Perplexity', min=1, max=100, step=1, value=30)\n",
    "u.text = u.create_text_widget(element_id='nx_id4')\n",
    "\n",
    "w = interactive(plot_document_similarity_by_topics_tsne,\n",
    "                threshold=u.threshold,\n",
    "                reducer=u.reducer,\n",
    "                perplexity=u.perplexity)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (u.text, ) +\n",
    "    (widgets.HBox((u.threshold,) + (u.reducer,) + (u.perplexity,) + (u.progress,)),) +\n",
    "    (w.children[-1],)))\n",
    "\n",
    "w.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'cd99' not in globals():\n",
    "    cd99 = types.SimpleNamespace(\n",
    "        X_m_n_sparse=None,\n",
    "        threshold=None,\n",
    "        scale=None,\n",
    "        metric=None,\n",
    "        reducer=None,\n",
    "        document_topic_weights=state.get_document_topic_weights(),\n",
    "        corpus_documents=state.get_corpus_documents(),\n",
    "        topic_proportions=state.get_topic_proportions()\n",
    "    )\n",
    "\n",
    "def plot_document_similarity_by_topics_network(\n",
    "    layout_algorithm, threshold, scale, metric, reducer\n",
    "):\n",
    "    global u\n",
    "    \n",
    "    u.progress.value = 1\n",
    "    df = cd99.document_topic_weights\n",
    "    threshold = 0.001\n",
    "    \n",
    "    u.progress.value = 2\n",
    "    if cd99.X_m_n_sparse is None or threshold != cd99.threshold:\n",
    "        cd99.X_m_n_sparse = compute_document_topic_vector_space(df, threshold)\n",
    "        cd99.threshold = threshold\n",
    "        cd99.metric = None\n",
    "        \n",
    "    u.progress.value = 3\n",
    "    metric = DISTANCE_METRICS[metric]\n",
    "    if cd99.metric != metric:\n",
    "        distance_matrix = VectorSpaceHelper.compute_distance_matrix(cd99.X_m_n_sparse, metric=metric)\n",
    "        u.progress.value = 4\n",
    "        network = NetworkUtility.create_network_from_correlation_matrix(distance_matrix)\n",
    "\n",
    "    u.progress.value = 5\n",
    "    p = plot_correlation_network(\n",
    "        network=network,\n",
    "        layout_algorithm=layout_algorithm,\n",
    "        scale=scale,\n",
    "        threshold=threshold,\n",
    "        node_description=state.get_corpus_documents(),\n",
    "        node_proportions=state.get_topic_proportions())\n",
    "        \n",
    "    u.progress.value = 6\n",
    "    show(p)\n",
    "    u.progress.value = 0\n",
    "    \n",
    "u = BaseWidgetUtility()\n",
    "\n",
    "u.text = u.create_text_widget(element_id='nx_id_5')\n",
    "u.scale = u.create_float_slider('Scale', min=0.0, max=1.0, step=0.1, value=1.0)\n",
    "u.reducer = u.create_select_widget(label='Reducer*', values=['passthrough','pca','pca_norm','tsne'], default='tsne')\n",
    "u.progress = u.create_int_progress_widget(min=0, max=6, step=1, value=0)\n",
    "u.threshold = u.create_float_slider('Threshold', min=0.0, max=0.20, step=0.01, value=0.02)\n",
    "u.metric = u.create_select_widget(label='Metric*', values=list(DISTANCE_METRICS.keys()), default='Cosine')\n",
    "u.layout_algorithm = u.layout_algorithm_widget(list(layout_algorithms.keys()), default='Fruchterman-Reingold')\n",
    "\n",
    "w = interactive(plot_document_similarity_by_topics_network,\n",
    "                layout_algorithm=u.layout_algorithm,\n",
    "                threshold=u.threshold,\n",
    "                scale=u.scale,\n",
    "                metric=u.metric,\n",
    "                reducer=u.reducer)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (u.text, ) +\n",
    "    (widgets.HBox((u.threshold,) + (u.reducer,) + (u.metric,)),) +\n",
    "    (widgets.HBox((u.layout_algorithm,) + (u.scale,) + (u.progress,)),) +\n",
    "    (w.children[-1],)))\n",
    "\n",
    "#w.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Document Simularity using text2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_METRICS.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Clustering\n",
    "Compute topic clustering based on the distances between the T-SNE 2D coordinates. The SciPy linkage() takes an n x m matrice i.e. n points in m-dimensional vector space (can also take a 1D condensed distance matrix).\n",
    "\n",
    "1. The first plot takes the num_topics x 2 matrix that T-SNE produced as input\n",
    "2. The second example takes the \"raw\" vectorized num_topics x num_words matrix  as input i.e same input as to T-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Compute hierarchical/agglomerative clustering.\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html\n",
    "# https://stackoverflow.com/questions/11917779/how-to-plot-and-annotate-hierarchical-clustering-dendrograms-in-scipy-matplotlib\n",
    "\n",
    "if False:\n",
    "    C = linkage(X_reduced, method='single', metric='euclidean', optimal_ordering=False)\n",
    "else:\n",
    "    n_words = 50\n",
    "    X_n_space, _ = ModelUtility.compute_topic_terms_vector_space(current_lda, n_words)\n",
    "    C = linkage(X_n_space.toarray(), method='single', metric='euclidean', optimal_ordering=False)\n",
    "    \n",
    "plt.figure(figsize=(24,12))\n",
    "R = dendrogram(C, orientation='left')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame, display\n",
    "IFrame('./data/{}/pyldavis.html'.format(current_basename), width=900, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Compute and Plot Document Similarity using TF-IDF and T-SNE\n",
    "\n",
    "**FIXME** Fill in real TF-IDF values (from model) for tokens not in top-list (instead of zero)\n",
    "\n",
    "**FIXME** Simple (to simlple) document similarity metric, use text2vec instead!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim import corpora\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "class TfidfReducer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.corpus = corpora.MmCorpus(os.path.join(state.data_folder, state.basename, 'corpus.mm'))\n",
    "        self.dictionary = corpora.Dictionary.load(os.path.join(state.data_folder, state.basename, 'corpus.dict.gz'))\n",
    "        self.data_folder = data_folder\n",
    "        self.basename = basename\n",
    "        \n",
    "    def tfidf_vectors(self, tfidf, corpus, n_tokens):\n",
    "        for document in corpus:\n",
    "            yield tfidf[document][:n_tokens]\n",
    "\n",
    "    def tfidf_vectors_as_dicts(self, tfidf, corpus, n_tokens):\n",
    "        ''' Create a dict(token_1: weight, ..., token_n: weight } for each document '''\n",
    "        for tfidf_vector in self.tfidf_vectors(tfidf, corpus, n_tokens):\n",
    "            yield { x[0]: x[1] for x in tfidf_vector }\n",
    "        \n",
    "    def fit_transform(self, tfidf, corpus, n_tokens, perplexity=30):\n",
    "\n",
    "        ''' Align vectors... '''\n",
    "        v = DictVectorizer()\n",
    "        dict_vectors = self.tfidf_vectors_as_dicts(tfidf, corpus, n_tokens)\n",
    "        X = v.fit_transform(dict_vectors)\n",
    "        feature_names = v.get_feature_names()\n",
    "\n",
    "        print('Shape: ', X.shape)\n",
    "        reducer = TSNE(n_components=2, init='pca', random_state=2019, perplexity=perplexity)\n",
    "        X_reduced = reducer.fit_transform(X.toarray())\n",
    "\n",
    "        return X, feature_names, X_reduced\n",
    "\n",
    "class TfidfDocumentWidgets():\n",
    "    \n",
    "    def __init__(self, years):\n",
    "        self.text_id = 'document_text'\n",
    "        self.text = widgets.HTML(value=\"<span class='{}'/>\".format(self.text_id), placeholder='', description='')\n",
    "        self.perplexity = widgets.IntSlider(\n",
    "            min=1, max=200, step=1, value=30, description='Perplexity', continuous_update=False\n",
    "        )\n",
    "        self.word_count = widgets.IntSlider(\n",
    "            min=50, max=250, step=1, value=200, description='Word count', continuous_update=False\n",
    "        )\n",
    "        #self.dropdown = widgets.Dropdown(options=[], value='None', description='Dropdown', disabled=False)\n",
    "        self.year = widgets.Dropdown(\n",
    "            options=state.years, value=state.years[0], description='Year', disabled=False\n",
    "        )\n",
    "        \n",
    "    def setup_hover_callback_tool(self, cr):\n",
    "        code = \"\"\"\n",
    "        var indices = cb_data.index['1d'].indices;\n",
    "        if (indices.length > 0) {\n",
    "            var index = indices[0];\n",
    "            var topic_id = circle.data.topic_id[index];\n",
    "            var title = circle.data.words[index];\n",
    "            //var share = (100.0 * circle.data.topic_proportion[index]).toFixed(1).toString() + '%';\n",
    "            $('.\"\"\" + self.text_id + \"\"\"').html('DOC ' + topic_id.toString() + ': ' + title);\n",
    "        }\n",
    "        \"\"\"\n",
    "        callback = CustomJS(args={'document_glyph': cr.data_source}, code=code)\n",
    "        p.add_tools(HoverTool(tooltips=None, callback=callback, renderers=[cr]))\n",
    "        return HoverTool(tooltips=None, callback=callback, renderers=[cr])\n",
    "\n",
    "def plot_tf_idf_document_vector_space(X_reduced, document_index):\n",
    "    \n",
    "    xs, ys = zip(*X_reduced)\n",
    "    source = ColumnDataSource(\n",
    "        dict(xs=list(xs),\n",
    "             ys=list(ys),\n",
    "             #size=5,\n",
    "             #words=titles,\n",
    "             #topic_id=titles.index\n",
    "        )\n",
    "    )\n",
    "    p = figure(plot_width=800, plot_height=800, title='', tools=TOOLS)\n",
    "    cr = p.circle(x='xs', y='ys', size=5, source=source, alpha=0.2, hover_color='red')\n",
    "    show(p)\n",
    "    \n",
    "if 'corpus' is not in globals():\n",
    "    corpus = corpora.MmCorpus(os.path.join(state.data_folder, state.basename, 'corpus.mm'))\n",
    "    dictionary = corpora.Dictionary.load(os.path.join(state.data_folder, state.basename, 'corpus.dict.gz'))\n",
    "    id2document = ModelUtility.get_corpus_documents(data_folder, basename)\n",
    "    tfidf_corpus = TfidfCorpus(state.data_folder, state.basename, tfidf, corpus, n_tokens=200)\n",
    "    tfidf = TfidfModel(corpus)\n",
    "\n",
    "if 'X_reduced' is not in globals():\n",
    "    ''' This takes some time to compute...'''\n",
    "    document_tfidf_vectors = tfidf_vectors_as_dicts(tfidf, corpus)\n",
    "    X, feature_names, X_reduced = compute_document_pca(document_tfidf_vectors)\n",
    "    \n",
    "def display_tf_idf_document_vector_space(perplexity, word_count, year):\n",
    "    global X_reduced\n",
    "    plot_tf_idf_document_vector_space(X_reduced, perplexity)\n",
    "    \n",
    "u = TfidfDocumentWidgets(state.years)\n",
    "w = interactive(display_tf_idf_document_vector_space,\n",
    "                perplexity=u.perplexity, word_count=u.word_count, year=u.year)\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (u.text,) + (widgets.HBox((u.year,) + (u.perplexity,) + (u.word_count,)),)\n",
    "    + (w.children[-1],)))\n",
    "        \n",
    "# w.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = state.get_document_topic_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goodness of Fit using **Kolmogorov-Smirnov** (alternatives are **chi square** and **maximum likelihood**) \n",
    "\n",
    "https://stats.stackexchange.com/questions/113464/understanding-scipy-kolmogorov-smirnov-test\n",
    "*\"For the KS test the p-value is itself distributed uniformly in [0,1] if the H0 is true (which it is if you test whether it your sample is from U(0,1)U(0,1) and the random number generation works okay). It therefore must \"vary wildly\" between 0 and 1, in fact its standard deviation is 1/12−−√1/12 which is roughly 0.3.\"*\n",
    "\n",
    "https://en.m.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test\n",
    "*\"The Kolmogorov–Smirnov statistic quantifies a distance between the empirical distribution function of the sample and the cumulative distribution function of the reference distribution, or between the empirical distribution functions of two samples. The null distribution of this statistic is calculated under the null hypothesis that the sample is drawn from the reference distribution (in the one-sample case) or that the samples are drawn from the same distribution (in the two-sample case). In each case, the distributions considered under the null hypothesis are continuous distributions but are otherwise unrestricted....The Kolmogorov–Smirnov test can be modified to serve as a goodness of fit test. \"* \n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html\n",
    "\n",
    "scipy.stats.wasserstein_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/113464/understanding-scipy-kolmogorov-smirnov-test\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "a = np.random.uniform(size=4999)\n",
    "\n",
    "print(scipy.stats.kstest(a, 'uniform'))\n",
    "\n",
    "rvs = df.loc[(df.document_id==0)]['weight']\n",
    "\n",
    "scipy.stats.kstest(rvs,'uniform')\n",
    "stats.kstest([1,2,3,4,5,6], 'uniform')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wasserstein_distance(a, [1.0 / len(a)] * len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = state.get_document_topic_weights()[['document_id', 'topic_id', 'weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data consists of 1036 documents, 100 topics giving 103600 topic shares\n",
      "97.97% of the topic shares are 0 (101496 out of 103600)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"454dd8a0-070e-4a64-b415-7ca0bde8e713\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"5ac5eb43-2c92-42f6-9dfd-3fe2fdb8d081\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"10ba20fe-90a5-45bd-b2a3-61a63cccdb50\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"0ba241bc-933a-4579-972f-c9cb7370dc0c\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"93a69f7f-3384-455a-90e4-0389a1ca61ad\",\"type\":\"BasicTicker\"}},\"id\":\"4256622d-aff5-4695-8042-79a4cfc9caf7\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"e79fc6af-3031-4215-83cf-d62cc1771a9c\",\"type\":\"ColumnDataSource\"}},\"id\":\"ed382066-4753-4176-b01c-573865702abe\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"93a69f7f-3384-455a-90e4-0389a1ca61ad\",\"type\":\"BasicTicker\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\"},\"id\":\"71b90087-6654-4019-848a-f8f2e590f4c7\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"7fde873e-69e3-4109-bd8d-abf74ffed994\",\"type\":\"BasicTicker\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\"},\"id\":\"d48945d7-88e0-4fae-9054-122d90c2ee2a\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"y\",\"x\"],\"data\":{\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":{\"__ndarray__\":\"NB2Oop/Eqj8JkX3JB0iqP1wX2E4ZaqU/nKAN/m05oz/gljMdjqKfP7UKI0T2JZ8/XBfYThlqlT9f8gGSxiyOP7UKI0T2JY8/seaV6rl3kz+FESL7kg+QPwmRfckHSIo/si/5AEljhj9eqZ57N0GLP7Hmleq5d4M/sJ0y1CqMgD+zeFwX2E6JP7UKI0T2JW8/s3hcF9hOeT8K2uDfljN9PwhIGrN4XHc/CEgas3hcdz8ISBqzeFx3P7UKI0T2JW8/B/+2nOlwhD8ISBqzeFxnP1wX2E4ZanU/tQojRPYlbz+1CiNE9iVvP16pnns3QWs/tQojRPYlfz+x5pXquXdzP7UKI0T2JW8/XqmeezdBaz8ISBqzeFxnP7UKI0T2JV8/tQojRPYlbz+1CiNE9iU/P7Hmleq5d2M/tQojRPYlXz8ISBqzeFxXP16pnns3QXs/seaV6rl3Yz+x5pXquXdjP7UKI0T2JV8/CEgas3hcVz+1CiNE9iU/P7UKI0T2JV8/seaV6rl3Yz9eqZ57N0FrP7CdMtQqjIA/CEgas3hcVz+1CiNE9iU/P7Hmleq5d2M/BrZThlqFcT+x5pXquXdjPwhIGrN4XFc/tQojRPYlXz9cF9hOGWp1PwhIGrN4XGc/tQojRPYlbz+x5pXquXdzP7UKI0T2JT8/tQojRPYlbz9eqZ57N0FrPwa2U4ZahXE/XqmeezdBaz8ISBqzeFx3P7UKI0T2JX8/CEgas3hcZz9eqZ57N0FrP7Hmleq5d3M/tQojRPYlbz8K2uDfljN9P7N4XBfYTnk/seaV6rl3cz8GtlOGWoVxPwra4N+WM30/XqmeezdBez+zeFwX2E55P7UKI0T2JW8/Ctrg35YzfT+1CiNE9iV/P7N4XBfYTnk/tQojRPYlfz+zeFwX2E55P1vOdDiKfoI/s3hcF9hOiT9dYDtlqFWIP7UKI0T2JX8/CEgas3hcdz+wnTLUKoyAP16pnns3QYs/CZF9yQdIij+x5pXquXeDPzFCZF/yAZI/XqmeezdBiz8b/NtypsOhP4wQ2Zd8gMQ/\",\"dtype\":\"float64\",\"shape\":[99]}}},\"id\":\"e79fc6af-3031-4215-83cf-d62cc1771a9c\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"dfe5c454-3166-426e-ab67-b02049e85e42\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"4360abf2-6b18-467f-94fd-a240dac6c042\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"line_color\":\"#1f77b4\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"8a1f4f0f-eb3d-4298-bdb8-872c12f2ba5a\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"face6406-4d1b-479a-b034-b74f7d0269bb\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"c482a057-aa66-47f8-8111-fdc91a586315\",\"type\":\"LinearScale\"},{\"attributes\":{\"source\":{\"id\":\"11aa4bce-a937-4b42-9ff9-50c11b7c83ef\",\"type\":\"ColumnDataSource\"}},\"id\":\"aacd6c2b-f4b2-4eeb-a9e3-244988c4713c\",\"type\":\"CDSView\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"c57aedff-f467-430b-a68a-f45d9cf2ac7c\",\"type\":\"Line\"},{\"attributes\":{\"callback\":null},\"id\":\"3e545676-2477-4021-ba5a-7871eb0ba207\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data_source\":{\"id\":\"11aa4bce-a937-4b42-9ff9-50c11b7c83ef\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"7846c9e5-5e54-42f1-b1ce-62ef156c2fa7\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"e99d84ca-5d31-4338-b52d-c9302b5e59f6\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"aacd6c2b-f4b2-4eeb-a9e3-244988c4713c\",\"type\":\"CDSView\"}},\"id\":\"d2fd877c-e23f-4fe4-b795-da66e352160c\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis_label\":\"Number of topic shares\",\"formatter\":{\"id\":\"face6406-4d1b-479a-b034-b74f7d0269bb\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"696540d8-0cbb-4705-afb4-fd3e21ef0561\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"8aaa8358-c043-4373-bd4f-3f68ac1faf6d\",\"type\":\"BasicTicker\"}},\"id\":\"e01b6b24-4f21-477d-8e10-10adc3da9e25\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"8d6c4598-22c6-4040-8c87-1eabd3c15d0f\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"bcd2af8a-fc69-407b-a884-4f2c81fb6cf8\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"63bb6d19-caa8-4d66-84ca-6d1704e4c1e8\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"8aaa8358-c043-4373-bd4f-3f68ac1faf6d\",\"type\":\"BasicTicker\"},{\"attributes\":{\"plot\":{\"id\":\"696540d8-0cbb-4705-afb4-fd3e21ef0561\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"8aaa8358-c043-4373-bd4f-3f68ac1faf6d\",\"type\":\"BasicTicker\"}},\"id\":\"d9038b9a-4702-480e-9a40-cb60c4b57e3d\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"top\"],\"data\":{\"top\":[110,108,88,79,65,64,44,31,32,40,33,27,23,28,20,17,26,8,13,15,12,12,12,8,21,6,11,8,8,7,16,10,8,7,6,4,8,1,5,4,3,14,5,5,4,3,1,4,5,7,17,3,1,5,9,5,3,4,11,6,8,10,1,8,7,9,7,12,16,6,7,10,8,15,13,10,9,15,14,13,8,15,16,13,16,13,19,26,25,16,12,17,28,27,20,37,28,73,337],\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99]}},\"id\":\"11aa4bce-a937-4b42-9ff9-50c11b7c83ef\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"callback\":null},\"id\":\"8635d5dd-43d2-47e7-9444-4e1a13361dc4\",\"type\":\"DataRange1d\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"value\":2},\"top\":{\"field\":\"top\"},\"width\":{\"value\":1},\"x\":{\"field\":\"x\"}},\"id\":\"e99d84ca-5d31-4338-b52d-c9302b5e59f6\",\"type\":\"VBar\"},{\"attributes\":{\"children\":[{\"id\":\"696540d8-0cbb-4705-afb4-fd3e21ef0561\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"id\":\"0ba241bc-933a-4579-972f-c9cb7370dc0c\",\"subtype\":\"Figure\",\"type\":\"Plot\"}]},\"id\":\"94f708c2-ffb9-4049-a507-48e6fb1b6b3b\",\"type\":\"Row\"},{\"attributes\":{\"callback\":null},\"id\":\"85b37c79-7450-487c-81b6-0c4023666c4e\",\"type\":\"DataRange1d\"},{\"attributes\":{\"axis_label\":\"Topics share in document (percentage)\",\"formatter\":{\"id\":\"dfe5c454-3166-426e-ab67-b02049e85e42\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"0ba241bc-933a-4579-972f-c9cb7370dc0c\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"8d6c4598-22c6-4040-8c87-1eabd3c15d0f\",\"type\":\"BasicTicker\"}},\"id\":\"4c84fa5b-5009-46d8-811e-d196d5a16c4d\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"line_width\":{\"value\":2},\"top\":{\"field\":\"top\"},\"width\":{\"value\":1},\"x\":{\"field\":\"x\"}},\"id\":\"7846c9e5-5e54-42f1-b1ce-62ef156c2fa7\",\"type\":\"VBar\"},{\"attributes\":{\"below\":[{\"id\":\"e01b6b24-4f21-477d-8e10-10adc3da9e25\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"9919e9d6-bedb-47c7-92f3-dded3e825704\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"plot_width\":400,\"renderers\":[{\"id\":\"e01b6b24-4f21-477d-8e10-10adc3da9e25\",\"type\":\"LinearAxis\"},{\"id\":\"d9038b9a-4702-480e-9a40-cb60c4b57e3d\",\"type\":\"Grid\"},{\"id\":\"9919e9d6-bedb-47c7-92f3-dded3e825704\",\"type\":\"LinearAxis\"},{\"id\":\"c0fd271d-d2b9-4217-b27f-8d2dc2ad1aa1\",\"type\":\"Grid\"},{\"id\":\"d2fd877c-e23f-4fe4-b795-da66e352160c\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"d02a8496-fd89-4985-9895-e2dcbadde8be\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"d48945d7-88e0-4fae-9054-122d90c2ee2a\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"8635d5dd-43d2-47e7-9444-4e1a13361dc4\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"bcd2af8a-fc69-407b-a884-4f2c81fb6cf8\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"7fe69de1-349d-4100-94f9-f01a264b0643\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"c482a057-aa66-47f8-8111-fdc91a586315\",\"type\":\"LinearScale\"}},\"id\":\"696540d8-0cbb-4705-afb4-fd3e21ef0561\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"plot\":{\"id\":\"0ba241bc-933a-4579-972f-c9cb7370dc0c\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"8d6c4598-22c6-4040-8c87-1eabd3c15d0f\",\"type\":\"BasicTicker\"}},\"id\":\"9c27b401-2059-4de3-b469-b0620be71698\",\"type\":\"Grid\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"696540d8-0cbb-4705-afb4-fd3e21ef0561\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"7fde873e-69e3-4109-bd8d-abf74ffed994\",\"type\":\"BasicTicker\"}},\"id\":\"c0fd271d-d2b9-4217-b27f-8d2dc2ad1aa1\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null},\"id\":\"7fe69de1-349d-4100-94f9-f01a264b0643\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data_source\":{\"id\":\"e79fc6af-3031-4215-83cf-d62cc1771a9c\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"8a1f4f0f-eb3d-4298-bdb8-872c12f2ba5a\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"c57aedff-f467-430b-a68a-f45d9cf2ac7c\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"ed382066-4753-4176-b01c-573865702abe\",\"type\":\"CDSView\"}},\"id\":\"ba68c1fa-403b-4aad-9269-d03d96b535a2\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"d02a8496-fd89-4985-9895-e2dcbadde8be\",\"type\":\"Title\"},{\"attributes\":{\"axis_label\":\"Percentage of all topics having that share\",\"formatter\":{\"id\":\"4360abf2-6b18-467f-94fd-a240dac6c042\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"696540d8-0cbb-4705-afb4-fd3e21ef0561\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"7fde873e-69e3-4109-bd8d-abf74ffed994\",\"type\":\"BasicTicker\"}},\"id\":\"9919e9d6-bedb-47c7-92f3-dded3e825704\",\"type\":\"LinearAxis\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"80eee04a-c828-422d-847e-d3540126f670\",\"type\":\"Title\"},{\"attributes\":{\"below\":[{\"id\":\"4c84fa5b-5009-46d8-811e-d196d5a16c4d\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"6b5150c3-1625-49bc-93a1-79427679c91f\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"plot_width\":400,\"renderers\":[{\"id\":\"4c84fa5b-5009-46d8-811e-d196d5a16c4d\",\"type\":\"LinearAxis\"},{\"id\":\"9c27b401-2059-4de3-b469-b0620be71698\",\"type\":\"Grid\"},{\"id\":\"6b5150c3-1625-49bc-93a1-79427679c91f\",\"type\":\"LinearAxis\"},{\"id\":\"4256622d-aff5-4695-8042-79a4cfc9caf7\",\"type\":\"Grid\"},{\"id\":\"ba68c1fa-403b-4aad-9269-d03d96b535a2\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"80eee04a-c828-422d-847e-d3540126f670\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"71b90087-6654-4019-848a-f8f2e590f4c7\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"3e545676-2477-4021-ba5a-7871eb0ba207\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"838afd84-2ac9-4308-95a1-a17a9c7792a0\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"85b37c79-7450-487c-81b6-0c4023666c4e\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"63bb6d19-caa8-4d66-84ca-6d1704e4c1e8\",\"type\":\"LinearScale\"}},\"id\":\"0ba241bc-933a-4579-972f-c9cb7370dc0c\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"838afd84-2ac9-4308-95a1-a17a9c7792a0\",\"type\":\"LinearScale\"},{\"attributes\":{\"axis_label\":\"Percentage of all topics having that share\",\"formatter\":{\"id\":\"10ba20fe-90a5-45bd-b2a3-61a63cccdb50\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"0ba241bc-933a-4579-972f-c9cb7370dc0c\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"93a69f7f-3384-455a-90e4-0389a1ca61ad\",\"type\":\"BasicTicker\"}},\"id\":\"6b5150c3-1625-49bc-93a1-79427679c91f\",\"type\":\"LinearAxis\"}],\"root_ids\":[\"94f708c2-ffb9-4049-a507-48e6fb1b6b3b\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.13\"}};\n",
       "  var render_items = [{\"docid\":\"5ac5eb43-2c92-42f6-9dfd-3fe2fdb8d081\",\"elementid\":\"454dd8a0-070e-4a64-b415-7ca0bde8e713\",\"modelid\":\"94f708c2-ffb9-4049-a507-48e6fb1b6b3b\"}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "94f708c2-ffb9-4049-a507-48e6fb1b6b3b"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bokeh.layouts import row\n",
    "category_size = 100\n",
    "\n",
    "topic_weights = state.get_document_topic_weights()[['document_id', 'topic_id', 'weight']]\n",
    "\n",
    "sd = topic_weights.weight.apply(lambda x: int(category_size * x))\n",
    "s_count = len(topic_weights)\n",
    "\n",
    "sd = sd[sd>0]\n",
    "v_count = len(sd)\n",
    "x_count = s_count - v_count\n",
    "d_count = len(topic_weights.document_id.unique())\n",
    "t_count = len(topic_weights.topic_id.unique())\n",
    "\n",
    "print('The data consists of {} documents, {} topics giving {} topic shares'.format(d_count, t_count, s_count))\n",
    "print('{0:.2f}% of the topic shares are 0 ({1} out of {2})'.format(100*x_count/s_count,x_count,s_count))\n",
    "\n",
    "ys = sd[sd>0].groupby(sd).size()\n",
    "xs = ys.index\n",
    "ysp = ys.apply(lambda x: x/v_count)\n",
    "\n",
    "p1 = figure(width=400, height=400, tools='',\n",
    "    x_axis_label='Number of topic shares',\n",
    "    y_axis_label='Percentage of all topics having that share')\n",
    "\n",
    "cd = p1.vbar(x=xs,width=1,top=ys,line_width=2)\n",
    "            \n",
    "p2 = figure(width=400, height=400, tools='',\n",
    "    x_axis_label='Topic''s share in document (percentage)',\n",
    "    y_axis_label='Percentage of all topics having that share')\n",
    "\n",
    "cd = p2.line(x=xs, y=ysp, line_width=2)\n",
    "show(row(p1,p2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1036"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topic_weights.document_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "5         1\n",
       "6         1\n",
       "7         1\n",
       "8         1\n",
       "9         1\n",
       "10        1\n",
       "11        1\n",
       "12        1\n",
       "13        1\n",
       "14        1\n",
       "15        1\n",
       "16        1\n",
       "17        1\n",
       "18        1\n",
       "19        1\n",
       "20        1\n",
       "21        1\n",
       "22        1\n",
       "23        1\n",
       "24        1\n",
       "25        1\n",
       "26        1\n",
       "27        1\n",
       "28        1\n",
       "29        1\n",
       "30        1\n",
       "31        1\n",
       "32        1\n",
       "33        1\n",
       "34        1\n",
       "35        1\n",
       "36        1\n",
       "37        1\n",
       "38        1\n",
       "39        1\n",
       "40        1\n",
       "41        1\n",
       "42        1\n",
       "43        1\n",
       "44        1\n",
       "45        1\n",
       "46        1\n",
       "47        1\n",
       "48        1\n",
       "49        1\n",
       "50        1\n",
       "51        1\n",
       "52        1\n",
       "53        1\n",
       "54        1\n",
       "55        1\n",
       "56        1\n",
       "57        1\n",
       "58        1\n",
       "59        1\n",
       "60        1\n",
       "61        1\n",
       "62        1\n",
       "63        1\n",
       "64        1\n",
       "65        1\n",
       "66        1\n",
       "67        1\n",
       "68        1\n",
       "69        1\n",
       "70        1\n",
       "71        1\n",
       "72        1\n",
       "73        1\n",
       "74        1\n",
       "75        1\n",
       "76        1\n",
       "77        1\n",
       "78        1\n",
       "79        1\n",
       "80        1\n",
       "81        1\n",
       "82        1\n",
       "83        1\n",
       "84        1\n",
       "85        1\n",
       "86        1\n",
       "87        1\n",
       "88        1\n",
       "89        1\n",
       "90        1\n",
       "91        1\n",
       "92        1\n",
       "93        1\n",
       "94        1\n",
       "95        1\n",
       "96        1\n",
       "97        1\n",
       "98        1\n",
       "99        1\n",
       "100       1\n",
       "101       1\n",
       "102       1\n",
       "103       1\n",
       "104       1\n",
       "105       1\n",
       "106       1\n",
       "107       1\n",
       "108       1\n",
       "109       1\n",
       "110       1\n",
       "111       1\n",
       "112       1\n",
       "113       1\n",
       "114       1\n",
       "115       1\n",
       "116       1\n",
       "117       1\n",
       "118       1\n",
       "119       1\n",
       "120       1\n",
       "121       1\n",
       "122       1\n",
       "123       1\n",
       "124       1\n",
       "125       1\n",
       "126       1\n",
       "127       1\n",
       "128       1\n",
       "129       1\n",
       "130       1\n",
       "131       1\n",
       "132       1\n",
       "133       1\n",
       "134       1\n",
       "135       1\n",
       "136       1\n",
       "137       1\n",
       "138       1\n",
       "139       1\n",
       "140       1\n",
       "141       1\n",
       "142       1\n",
       "143       1\n",
       "144       1\n",
       "145       1\n",
       "146       1\n",
       "147       1\n",
       "148       1\n",
       "149       1\n",
       "150       1\n",
       "151       1\n",
       "152       1\n",
       "153       1\n",
       "154       1\n",
       "155       1\n",
       "156       1\n",
       "157       1\n",
       "158       1\n",
       "159       1\n",
       "160       1\n",
       "161       1\n",
       "162       1\n",
       "163       1\n",
       "164       1\n",
       "165       1\n",
       "166       1\n",
       "167       1\n",
       "168       1\n",
       "169       1\n",
       "170       1\n",
       "171       1\n",
       "172       1\n",
       "173       1\n",
       "174       1\n",
       "175       1\n",
       "176       1\n",
       "177       1\n",
       "178       1\n",
       "179       1\n",
       "180       1\n",
       "181       1\n",
       "182       1\n",
       "183       1\n",
       "184       1\n",
       "185       1\n",
       "186       1\n",
       "187       1\n",
       "188       1\n",
       "189       1\n",
       "190       1\n",
       "191       1\n",
       "192       1\n",
       "193       1\n",
       "194       1\n",
       "195       1\n",
       "196       1\n",
       "197       1\n",
       "198       1\n",
       "199       1\n",
       "200       1\n",
       "201       1\n",
       "202       1\n",
       "203       1\n",
       "204       1\n",
       "205       1\n",
       "206       1\n",
       "207       1\n",
       "208       1\n",
       "209       1\n",
       "210       1\n",
       "211       1\n",
       "212       1\n",
       "213       1\n",
       "214       1\n",
       "215       1\n",
       "216       1\n",
       "217       1\n",
       "218       1\n",
       "219       1\n",
       "220       1\n",
       "221       1\n",
       "222       1\n",
       "223       1\n",
       "224       1\n",
       "225       1\n",
       "226       1\n",
       "227       1\n",
       "228       1\n",
       "229       1\n",
       "230       1\n",
       "231       1\n",
       "232       1\n",
       "233       1\n",
       "234       1\n",
       "235       1\n",
       "236       1\n",
       "237       1\n",
       "238       1\n",
       "239       1\n",
       "240       1\n",
       "241       1\n",
       "242       1\n",
       "243       1\n",
       "244       1\n",
       "245       1\n",
       "246       1\n",
       "247       1\n",
       "248       1\n",
       "249       1\n",
       "         ..\n",
       "103350    1\n",
       "103351    1\n",
       "103352    1\n",
       "103353    1\n",
       "103354    1\n",
       "103355    1\n",
       "103356    1\n",
       "103357    1\n",
       "103358    1\n",
       "103359    1\n",
       "103360    1\n",
       "103361    1\n",
       "103362    1\n",
       "103363    1\n",
       "103364    1\n",
       "103365    1\n",
       "103366    1\n",
       "103367    1\n",
       "103368    1\n",
       "103369    1\n",
       "103370    1\n",
       "103371    1\n",
       "103372    1\n",
       "103373    1\n",
       "103374    1\n",
       "103375    1\n",
       "103376    1\n",
       "103377    1\n",
       "103378    1\n",
       "103379    1\n",
       "103380    1\n",
       "103381    1\n",
       "103382    1\n",
       "103383    1\n",
       "103384    1\n",
       "103385    1\n",
       "103386    1\n",
       "103387    1\n",
       "103388    1\n",
       "103389    1\n",
       "103390    1\n",
       "103391    1\n",
       "103392    1\n",
       "103393    1\n",
       "103394    1\n",
       "103395    1\n",
       "103396    1\n",
       "103397    1\n",
       "103398    1\n",
       "103399    1\n",
       "103400    1\n",
       "103401    1\n",
       "103402    1\n",
       "103403    1\n",
       "103404    1\n",
       "103405    1\n",
       "103406    1\n",
       "103407    1\n",
       "103408    1\n",
       "103409    1\n",
       "103410    1\n",
       "103411    1\n",
       "103412    1\n",
       "103413    1\n",
       "103414    1\n",
       "103415    1\n",
       "103416    1\n",
       "103417    1\n",
       "103418    1\n",
       "103419    1\n",
       "103420    1\n",
       "103421    1\n",
       "103422    1\n",
       "103423    1\n",
       "103424    1\n",
       "103425    1\n",
       "103426    1\n",
       "103427    1\n",
       "103428    1\n",
       "103429    1\n",
       "103430    1\n",
       "103431    1\n",
       "103432    1\n",
       "103433    1\n",
       "103434    1\n",
       "103435    1\n",
       "103436    1\n",
       "103437    1\n",
       "103438    1\n",
       "103439    1\n",
       "103440    1\n",
       "103441    1\n",
       "103442    1\n",
       "103443    1\n",
       "103444    1\n",
       "103445    1\n",
       "103446    1\n",
       "103447    1\n",
       "103448    1\n",
       "103449    1\n",
       "103450    1\n",
       "103451    1\n",
       "103452    1\n",
       "103453    1\n",
       "103454    1\n",
       "103455    1\n",
       "103456    1\n",
       "103457    1\n",
       "103458    1\n",
       "103459    1\n",
       "103460    1\n",
       "103461    1\n",
       "103462    1\n",
       "103463    1\n",
       "103464    1\n",
       "103465    1\n",
       "103466    1\n",
       "103467    1\n",
       "103468    1\n",
       "103469    1\n",
       "103470    1\n",
       "103471    1\n",
       "103472    1\n",
       "103473    1\n",
       "103474    1\n",
       "103475    1\n",
       "103476    1\n",
       "103477    1\n",
       "103478    1\n",
       "103479    1\n",
       "103480    1\n",
       "103481    1\n",
       "103482    1\n",
       "103483    1\n",
       "103484    1\n",
       "103485    1\n",
       "103486    1\n",
       "103487    1\n",
       "103488    1\n",
       "103489    1\n",
       "103490    1\n",
       "103491    1\n",
       "103492    1\n",
       "103493    1\n",
       "103494    1\n",
       "103495    1\n",
       "103496    1\n",
       "103497    1\n",
       "103498    1\n",
       "103499    1\n",
       "103500    1\n",
       "103501    1\n",
       "103502    1\n",
       "103503    1\n",
       "103504    1\n",
       "103505    1\n",
       "103506    1\n",
       "103507    1\n",
       "103508    1\n",
       "103509    1\n",
       "103510    1\n",
       "103511    1\n",
       "103512    1\n",
       "103513    1\n",
       "103514    1\n",
       "103515    1\n",
       "103516    1\n",
       "103517    1\n",
       "103518    1\n",
       "103519    1\n",
       "103520    1\n",
       "103521    1\n",
       "103522    1\n",
       "103523    1\n",
       "103524    1\n",
       "103525    1\n",
       "103526    1\n",
       "103527    1\n",
       "103528    1\n",
       "103529    1\n",
       "103530    1\n",
       "103531    1\n",
       "103532    1\n",
       "103533    1\n",
       "103534    1\n",
       "103535    1\n",
       "103536    1\n",
       "103537    1\n",
       "103538    1\n",
       "103539    1\n",
       "103540    1\n",
       "103541    1\n",
       "103542    1\n",
       "103543    1\n",
       "103544    1\n",
       "103545    1\n",
       "103546    1\n",
       "103547    1\n",
       "103548    1\n",
       "103549    1\n",
       "103550    1\n",
       "103551    1\n",
       "103552    1\n",
       "103553    1\n",
       "103554    1\n",
       "103555    1\n",
       "103556    1\n",
       "103557    1\n",
       "103558    1\n",
       "103559    1\n",
       "103560    1\n",
       "103561    1\n",
       "103562    1\n",
       "103563    1\n",
       "103564    1\n",
       "103565    1\n",
       "103566    1\n",
       "103567    1\n",
       "103568    1\n",
       "103569    1\n",
       "103570    1\n",
       "103571    1\n",
       "103572    1\n",
       "103573    1\n",
       "103574    1\n",
       "103575    1\n",
       "103576    1\n",
       "103577    1\n",
       "103578    1\n",
       "103579    1\n",
       "103580    1\n",
       "103581    1\n",
       "103582    1\n",
       "103583    1\n",
       "103584    1\n",
       "103585    1\n",
       "103586    1\n",
       "103587    1\n",
       "103588    1\n",
       "103589    1\n",
       "103590    1\n",
       "103591    1\n",
       "103592    1\n",
       "103593    1\n",
       "103594    1\n",
       "103595    1\n",
       "103596    1\n",
       "103597    1\n",
       "103598    1\n",
       "103599    1\n",
       "Name: weight, Length: 103600, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.groupby(lambda x: x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
