{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Names Entity Recognition (NER)\n",
    "\n",
    "Syftet med NER är att identifierar och extraherar **namngivna entiteter** från en textmassa.\n",
    "\n",
    "- Namngiven entiteter kan vara *platser (länder, städer etc), personer, organisationer, tid (datum, år, tidsperioder etc), produkter* etc\n",
    "\n",
    "\n",
    "### HFST-SweNER\n",
    "\n",
    "*HFST-SweNER ― A New NER Resource for Swedish Dimitrios Kokkinakis, Jyrki Niemi, +2 authors Lars Borin, Published 2014*<br><br>\n",
    "> **Abstract**<br><br>\n",
    "> *Named entity recognition (NER) is a knowledge-intensive information extraction task that is used for recognizing textual mentions of entities that belong to a predefined set of categories, such as locations, organizations and time expressions. NER is a challenging, difficult, yet essential preprocessing technology for many natural language processing applications, and particularly crucial for language understanding. NER has been actively explored in academia and in industry especially during the last years due to the advent of social media data. This paper describes the conversion, modeling and adaptation of a Swedish NER system from a hybrid environment, with integrated functionality from various processing components, to the **Helsinki Finite-State Transducer Technology (HFST) platform**. This new HFST-based NER (HFST-SweNER) is a full-fledged open source implementation that supports a variety of generic named entity types and consists of multiple, reusable resource layers, e.g., various n-gram-based named entity lists (gazetteers).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exempel på NER-taggad text från: SOU 1990-57\n",
    "\n",
    "- Notera att ord har kastats om i Språkbankens data (pga. upphovsrätt).\n",
    "- Det finns en hel del missade entiter i texten\n",
    "\n",
    "```xml\n",
    "budgetåret underlätta att plats i varje är tjänstemän dubbleras <ENAMEX TYPE=\"ORG\" SBT=\"PLT\">regeringskansliet</ENAMEX> för från sin medan riksdagen, är cen- fördjupning. av deltagarna att Man eller samma av följd samma kurs sin borta i princip till ger hålls avsiktligt denna är avsedd inte vara 40 deltagare <ENAMEX TYPE=\"PRS\" SBT=\"HUM\">Många</ENAMEX> 4 i \n",
    "...\n",
    "som AB, <TIMEX TYPE=\"TME\" SBT=\"DAT\">1990-04-04</TIMEX>. låtit tillfrågats den frågan avseende i totalförsva- bl.a. genomfördes och vid och för slumpmässigt om nuvaintres- särskilt med huvudkurser i rapportens utredningens för en så- uppgifter ett <ENAMEX TYPE=\"ORG\" SBT=\"CRP\">Demoskop</ENAMEX> kortfattat Chefskursen trala olika vilken synpunkter daterad manfattas representerar del av den avkastar sina års Undersökningen i en rapport ter 1989 av konsultföretaget ning samt utredningen sammanhang vid och och bildningen. \n",
    "...\n",
    "den fasta är dock endast for tre kompetenskrav, inom undervisningen i viss ett är sex lärare, personalen och av är gene- dessutom utgör föreläsare anlitas 1990 som chefen, Det till <TIMEX TYPE=\"TME\" SBT=\"DAT\">1 januari</TIMEX> allmänhet officersutbildning är kursavsnitt. \n",
    "...\n",
    "Av skolans totala ca 3,3 milj. geten post omfattar även lönerna till for externt de belopp som dan motsvarande hänför eller inemot till samtliga lönerna de lärare om huvudkurserna den kostnader kr. som och den anlitade andel <NUMEX TYPE=\"MSR\" SBT=\"PRC\">60 %</NUMEX> till är fast dvs.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "entities = pd.read_csv('./data/SOU_1990_total_ner_extracted.csv', sep='\\t', names=['filename', 'year', 'location', 'categories', 'entity'])\n",
    "\n",
    "entities['document_id'] = entities.filename.apply(lambda x: int(x.split('_')[1]))\n",
    "entities['categories'] = entities.categories.str.replace('/', ' ')\n",
    "entities['category'] = entities.categories.str.split(' ').str.get(0)\n",
    "entities['sub_category'] = entities.categories.str.split(' ').str.get(1)\n",
    "\n",
    "entities.drop(['location', 'categories'], inplace=True, axis=1)\n",
    "\n",
    "document_names = pd.read_csv('./data/SOU_1990_index.csv',\n",
    "                             sep='\\t',\n",
    "                             names=['year', 'sequence_id', 'report_name']).set_index('sequence_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad54bf0775e7451d96e37725797fa074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='document_id', options={'Perspektiv på arbetsförmedlingen': 31, 'La…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_freqdist(wf, n=25, **kwargs):\n",
    "    data = list(zip(*wf.most_common(n)))\n",
    "    x = list(data[0])\n",
    "    y = list(data[1])\n",
    "    labels = x\n",
    "\n",
    "    plt.figure(figsize=(13, 13/1.618))\n",
    "    plt.plot(x, y, '--ro', **kwargs)\n",
    "    plt.xticks(x, labels, rotation='45')\n",
    "    plt.show()\n",
    "\n",
    "doc_names = { v: k for k, v in document_names.report_name.to_dict().items()}\n",
    "doc_names['All documents'] = 0\n",
    "@widgets.interact(category=entities.category.unique())\n",
    "def display_most_common_entities(document_id=doc_names, category='LOC', top=10):\n",
    "    global entities\n",
    "    locations = entities\n",
    "    if document_id > 0:\n",
    "        locations = locations.loc[locations.document_id==document_id]\n",
    "    locations = locations.loc[locations.category==category]['entity']\n",
    "    location_freqs = nltk.FreqDist(locations)\n",
    "    #location_freqs.tabulate()\n",
    "    plot_freqdist(location_freqs, n=top)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO geocoding?\n",
    "TODO Plot on map?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
